{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/prashant/incedo/test/Dataset2147b1d/train_file.csv')\n",
    "test = pd.read_csv('/home/prashant/incedo/test/Dataset2147b1d/test_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Patient_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['YEAR'].unique()\n",
    "x.sort()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LocationDesc'] = data['LocationDesc'].map(lambda x: x.lower())\n",
    "test['LocationDesc'] = test['LocationDesc'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LocationDesc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 <= drugs \n",
    "# 0 <= alcohol\n",
    "\n",
    "data['Subtopic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat_columns = ['Sex', 'Race', 'StratificationType', 'LocationDesc', 'YEAR', 'QuestionCode']\n",
    "data[cat_columns] = data[cat_columns].astype('category')\n",
    "data[cat_columns] = data[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "test[cat_columns] = test[cat_columns].astype('category')\n",
    "test[cat_columns] = test[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['Greater_Risk_Question', 'Description','GeoLocation'],axis=1)\n",
    "test = test.drop(['Greater_Risk_Question', 'Description','GeoLocation'],axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y_train = data['Greater_Risk_Probability']\n",
    "x_train = data.drop(['Greater_Risk_Probability'],axis =1)\n",
    "\n",
    "X_train, X_test, y_train_internal, y_test_internal = train_test_split(x_train,y_train ,test_size =.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from subprocess import check_output\n",
    "# from datetime import time\n",
    "# import numpy as np\n",
    "# # Establish model\n",
    "# model = RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "# estimators = np.arange(10, 200, 10)\n",
    "# scores = []\n",
    "# for n in estimators:\n",
    "#     model.set_params(n_estimators=n)\n",
    "#     model.fit(X_train, y_train_internal)\n",
    "#     scores.append(model.score(X_test, y_test_internal))\n",
    "# plt.title(\"Effect of n_estimators\")\n",
    "# plt.xlabel(\"n_estimator\")\n",
    "# plt.ylabel(\"score\")\n",
    "# plt.plot(estimators, scores)\n",
    "\n",
    "params = {\n",
    "'num_leaves': 15,\n",
    "'max_bin': 100,\n",
    "'min_data_in_leaf': 45,\n",
    "'learning_rate': 0.01,\n",
    "'min_sum_hessian_in_leaf': 0.000446,\n",
    "'bagging_fraction': 0.55,\n",
    "'bagging_freq': 5,\n",
    "'max_depth': 14,\n",
    "'save_binary': True,\n",
    "'seed': 31452,\n",
    "'feature_fraction_seed': 31415,\n",
    "'feature_fraction': 0.51,\n",
    "'bagging_seed': 31415,\n",
    "'drop_seed': 31415,\n",
    "'data_random_seed': 31415,\n",
    "#'objective': 'multiclass',\n",
    "'boosting_type': 'gbdt',\n",
    "'verbose': 1,\n",
    "'metric': 'rmse',\n",
    "#'is_unbalance': False,\n",
    "#     'categorical_feature': \"name:branch_id\"\n",
    "# 'scale_pos_weight': len(train_df[\"target\"] == 0) / sum(train_df[\"target\"])\n",
    "}\n",
    "\n",
    "# Import the model we are using\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "# from tpot import TPOTClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "d_train = lgb.Dataset(X_train, label=y_train_internal)\n",
    "# Instantiate model with 1000 decision trees\n",
    "#rf = RandomForestClassifier()\n",
    "\n",
    "# Train the model on training data\n",
    "#rm = rf.fit(X_train, y_train_internal)\n",
    "rf = lgb.train(params, d_train,20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_internal = rf.predict(test)\n",
    "pred_internal = [round(pred) for pred in pred_internal]\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'Patient_ID': test['Patient_ID'], 'Greater_Risk_Probability': pred_internal})\n",
    "sub.to_csv('tod_app_lgb.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
