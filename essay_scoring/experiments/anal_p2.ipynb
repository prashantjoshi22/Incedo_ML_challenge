{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.corpus import stopwords\n",
    "from string import digits\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "stop=[]\n",
    "stop.extend(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(s):\n",
    "    s = s.lower()\n",
    "    data = re.sub(r'[^\\x00-\\x7F]+', ' ', s)\n",
    "    final_str = data.translate(str.maketrans('', '', string.punctuation))\n",
    "    filter_str = final_str.translate(str.maketrans('', '', digits))\n",
    "    nltk_tokens = nltk.word_tokenize(filter_str)\n",
    "    #Next find the roots of the word\n",
    "    str_= ''\n",
    "    for w in nltk_tokens:\n",
    "\n",
    "        if w not in stop:\n",
    "            str_ += ' '  + (lemmatizer.lemmatize(w))\n",
    "    \n",
    "    return str_.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>The procedures I think they should have includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>In order to replicate this experiment, you wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>above_average</td>\n",
       "      <td>above_average</td>\n",
       "      <td>In order to replicate their experiment, you wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1676</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>Pleace a simple of one material into one conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1677</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>Determin the mass of four different samples ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Essayset  min_score  max_score        clarity       coherent  \\\n",
       "0  1673         1          0          3        average          worst   \n",
       "1  1674         1          0          3        average          worst   \n",
       "2  1675         1          0          3  above_average  above_average   \n",
       "3  1676         1          0          3          worst          worst   \n",
       "4  1677         1          0          3          worst          worst   \n",
       "\n",
       "                                           EssayText  \n",
       "0  The procedures I think they should have includ...  \n",
       "1  In order to replicate this experiment, you wou...  \n",
       "2  In order to replicate their experiment, you wo...  \n",
       "3  Pleace a simple of one material into one conta...  \n",
       "4  Determin the mass of four different samples ma...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test_dataset.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['source_'] = 1\n",
    "df_test['source_'] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_train,df_test])\n",
    "df.loc[df['source_']==0]\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(['index'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_datasets = {}\n",
    "groups = df.groupby('Essayset')\n",
    "for name, group in groups:\n",
    "    multi_datasets[name] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1696, 13)\n"
     ]
    }
   ],
   "source": [
    "single_df = multi_datasets[2]\n",
    "print(single_df.shape)\n",
    "single_df.head()\n",
    "single_df.reset_index(inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7d91d5cb3c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msingle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candi_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score_2'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_3'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_4'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msingle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candi_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msingle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candi_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msingle_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score_2'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_3'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_4'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7d91d5cb3c34>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msingle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candi_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score_2'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_3'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_4'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msingle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candi_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msingle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'candi_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msingle_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score_2'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_3'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_4'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m'score_5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "single_df['candi_score'] = single_df[['score_1','score_2' ,'score_3' ,'score_4' ,'score_5']].mean(axis=1)\n",
    "single_df['candi_score'] = list(map(lambda x : round(x),single_df['candi_score']))\n",
    "single_df.drop(['score_1','score_2' ,'score_3' ,'score_4' ,'score_5','ID','index'],inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EssayText</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>max_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>source_</th>\n",
       "      <th>candi_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Changing the type of grafin would improve the ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Concluding from the students data that plastic...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>above_average</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two ways that the stundent could've improved t...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A conclusion I can make from this experiment i...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a.One conclusion I can draw is that plastic B ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>above_average</td>\n",
       "      <td>average</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           EssayText  Essayset        clarity  \\\n",
       "0  Changing the type of grafin would improve the ...       2.0        average   \n",
       "1  Concluding from the students data that plastic...       2.0      excellent   \n",
       "2  Two ways that the stundent could've improved t...       2.0        average   \n",
       "3  A conclusion I can make from this experiment i...       2.0        average   \n",
       "4  a.One conclusion I can draw is that plastic B ...       2.0  above_average   \n",
       "\n",
       "        coherent  max_score  min_score  source_  candi_score  \n",
       "0          worst          3          0        1            1  \n",
       "1  above_average          3          0        1            3  \n",
       "2          worst          3          0        1            1  \n",
       "3          worst          3          0        1            1  \n",
       "4        average          3          0        1            3  "
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(single_df.shape)\n",
    "single_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New feture percentage match \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df['kitna_aacha']=single_df['candi_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EssayText</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>max_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>source_</th>\n",
       "      <th>candi_score</th>\n",
       "      <th>kitna_aacha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Changing the type of grafin would improve the ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Concluding from the students data that plastic...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>above_average</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two ways that the stundent could've improved t...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A conclusion I can make from this experiment i...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a.One conclusion I can draw is that plastic B ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>above_average</td>\n",
       "      <td>average</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           EssayText  Essayset        clarity  \\\n",
       "0  Changing the type of grafin would improve the ...       2.0        average   \n",
       "1  Concluding from the students data that plastic...       2.0      excellent   \n",
       "2  Two ways that the stundent could've improved t...       2.0        average   \n",
       "3  A conclusion I can make from this experiment i...       2.0        average   \n",
       "4  a.One conclusion I can draw is that plastic B ...       2.0  above_average   \n",
       "\n",
       "        coherent  max_score  min_score  source_  candi_score  kitna_aacha  \n",
       "0          worst          3          0        1            1            1  \n",
       "1  above_average          3          0        1            3            3  \n",
       "2          worst          3          0        1            1            1  \n",
       "3          worst          3          0        1            1            1  \n",
       "4        average          3          0        1            3            3  "
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(single_df.shape)\n",
    "single_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df.drop(['min_score','max_score','Essayset','candi_score'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EssayText</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>source_</th>\n",
       "      <th>kitna_aacha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Changing the type of grafin would improve the ...</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Concluding from the students data that plastic...</td>\n",
       "      <td>excellent</td>\n",
       "      <td>above_average</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two ways that the stundent could've improved t...</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A conclusion I can make from this experiment i...</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a.One conclusion I can draw is that plastic B ...</td>\n",
       "      <td>above_average</td>\n",
       "      <td>average</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           EssayText        clarity  \\\n",
       "0  Changing the type of grafin would improve the ...        average   \n",
       "1  Concluding from the students data that plastic...      excellent   \n",
       "2  Two ways that the stundent could've improved t...        average   \n",
       "3  A conclusion I can make from this experiment i...        average   \n",
       "4  a.One conclusion I can draw is that plastic B ...  above_average   \n",
       "\n",
       "        coherent  source_  kitna_aacha  \n",
       "0          worst        1            1  \n",
       "1  above_average        1            3  \n",
       "2          worst        1            1  \n",
       "3          worst        1            1  \n",
       "4        average        1            3  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(single_df.shape)\n",
    "single_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "excellent        412\n",
       "above_average    365\n",
       "average          235\n",
       "worst            213\n",
       "Name: clarity, dtype: int64"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_df['clarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text  = []\n",
    "single_df['EssayText']=single_df['EssayText'].apply(preprocess_data)\n",
    "all_text = list(single_df['EssayText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1225"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='latin-1', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=20,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True,use_idf=True, min_df=20, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "tfidf.fit(all_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tfidf.transform(single_df['EssayText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>source_</th>\n",
       "      <th>kitna_aacha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1672</td>\n",
       "      <td>changing type grafin would improve student exp...</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1673</td>\n",
       "      <td>concluding student data plastic type b stretch...</td>\n",
       "      <td>excellent</td>\n",
       "      <td>above_average</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1674</td>\n",
       "      <td>two way stundent couldve improved experiment g...</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1675</td>\n",
       "      <td>conclusion make experiment plastic type b stre...</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1676</td>\n",
       "      <td>aone conclusion draw plastic b stretched plast...</td>\n",
       "      <td>above_average</td>\n",
       "      <td>average</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0                                          EssayText        clarity  \\\n",
       "0     1672  changing type grafin would improve student exp...        average   \n",
       "1     1673  concluding student data plastic type b stretch...      excellent   \n",
       "2     1674  two way stundent couldve improved experiment g...        average   \n",
       "3     1675  conclusion make experiment plastic type b stre...        average   \n",
       "4     1676  aone conclusion draw plastic b stretched plast...  above_average   \n",
       "\n",
       "        coherent  source_  kitna_aacha  \n",
       "0          worst        1            1  \n",
       "1  above_average        1            3  \n",
       "2          worst        1            1  \n",
       "3          worst        1            1  \n",
       "4        average        1            3  "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 290)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>kitna_aacha</th>\n",
       "      <th>source_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>above_average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>above_average</td>\n",
       "      <td>average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...     280  281  282  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "\n",
       "   283  284  285        clarity       coherent  kitna_aacha  source_  \n",
       "0  0.0  0.0  0.0        average          worst          1.0      1.0  \n",
       "1  0.0  0.0  0.0      excellent  above_average          3.0      1.0  \n",
       "2  0.0  0.0  0.0        average          worst          1.0      1.0  \n",
       "3  0.0  0.0  0.0        average          worst          1.0      1.0  \n",
       "4  0.0  0.0  0.0  above_average        average          3.0      1.0  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tfidf_features = pd.DataFrame(features.toarray())\n",
    "new_tfidf_features['clarity'] = single_df['clarity']\n",
    "new_tfidf_features['coherent'] = single_df['coherent']\n",
    "new_tfidf_features['kitna_aacha'] = single_df['kitna_aacha']\n",
    "new_tfidf_features['source_'] = single_df['source_']\n",
    "\n",
    "print(new_tfidf_features.shape)\n",
    "new_tfidf_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>kitna_aacha</th>\n",
       "      <th>source_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>above_average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>above_average</td>\n",
       "      <td>average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...     280  281  282  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "\n",
       "   283  284  285        clarity       coherent  kitna_aacha  source_  \n",
       "0  0.0  0.0  0.0        average          worst          1.0      1.0  \n",
       "1  0.0  0.0  0.0      excellent  above_average          3.0      1.0  \n",
       "2  0.0  0.0  0.0        average          worst          1.0      1.0  \n",
       "3  0.0  0.0  0.0        average          worst          1.0      1.0  \n",
       "4  0.0  0.0  0.0  above_average        average          3.0      1.0  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tfidf_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tfidf_features['clarity']=new_tfidf_features['clarity'].fillna(new_tfidf_features['clarity'].mode()[0])\n",
    "new_tfidf_features['coherent']=new_tfidf_features['coherent'].fillna(new_tfidf_features['coherent'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>kitna_aacha</th>\n",
       "      <th>source_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>above_average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>above_average</td>\n",
       "      <td>average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...     280  281  282  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   ...     0.0  0.0  0.0   \n",
       "\n",
       "   283  284  285        clarity       coherent  kitna_aacha  source_  \n",
       "0  0.0  0.0  0.0        average          worst          1.0      1.0  \n",
       "1  0.0  0.0  0.0      excellent  above_average          3.0      1.0  \n",
       "2  0.0  0.0  0.0        average          worst          1.0      1.0  \n",
       "3  0.0  0.0  0.0        average          worst          1.0      1.0  \n",
       "4  0.0  0.0  0.0  above_average        average          3.0      1.0  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tfidf_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tfidf_features.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1181, 290)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tfidf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preprocessed_single_q_data =  pd.get_dummies(new_tfidf_features,columns=['clarity' ,'coherent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>kitna_aacha</th>\n",
       "      <th>source_</th>\n",
       "      <th>clarity_above_average</th>\n",
       "      <th>clarity_average</th>\n",
       "      <th>clarity_excellent</th>\n",
       "      <th>clarity_worst</th>\n",
       "      <th>coherent_above_average</th>\n",
       "      <th>coherent_average</th>\n",
       "      <th>coherent_excellent</th>\n",
       "      <th>coherent_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9       ...        \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       ...         \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       ...         \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       ...         \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       ...         \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0       ...         \n",
       "\n",
       "   kitna_aacha  source_  clarity_above_average  clarity_average  \\\n",
       "0          1.0      1.0                      0                1   \n",
       "1          3.0      1.0                      0                0   \n",
       "2          1.0      1.0                      0                1   \n",
       "3          1.0      1.0                      0                1   \n",
       "4          3.0      1.0                      1                0   \n",
       "\n",
       "   clarity_excellent  clarity_worst  coherent_above_average  coherent_average  \\\n",
       "0                  0              0                       0                 0   \n",
       "1                  1              0                       1                 0   \n",
       "2                  0              0                       0                 0   \n",
       "3                  0              0                       0                 0   \n",
       "4                  0              0                       0                 1   \n",
       "\n",
       "   coherent_excellent  coherent_worst  \n",
       "0                   0               1  \n",
       "1                   0               0  \n",
       "2                   0               1  \n",
       "3                   0               1  \n",
       "4                   0               0  \n",
       "\n",
       "[5 rows x 296 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preprocessed_single_q_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_main_test = all_preprocessed_single_q_data.loc[all_preprocessed_single_q_data['source_'] == 0]\n",
    "preprocessed_main_train = all_preprocessed_single_q_data.loc[all_preprocessed_single_q_data['source_'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (preprocessed_main_train['kitna_aacha'])\n",
    "x_train = preprocessed_main_train.drop(['kitna_aacha'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1181, 295)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train_internal, y_test_internal = train_test_split(x_train,y_train ,test_size =0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>kitna_aacha</th>\n",
       "      <th>source_</th>\n",
       "      <th>clarity_above_average</th>\n",
       "      <th>clarity_average</th>\n",
       "      <th>clarity_excellent</th>\n",
       "      <th>clarity_worst</th>\n",
       "      <th>coherent_above_average</th>\n",
       "      <th>coherent_average</th>\n",
       "      <th>coherent_excellent</th>\n",
       "      <th>coherent_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 296 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_main_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 296)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-461-8dd7e5475c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train the model on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_internal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpred_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_main_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"classes_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         return (safe_sparse_dot(X, self.feature_log_prob_.T) +\n\u001b[1;32m    732\u001b[0m                 self.class_log_prior_)\n",
      "\u001b[0;32m~/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    580\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 582\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 296)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = MultinomialNB()\n",
    "\n",
    "# Train the model on training data\n",
    "rm = rf.fit(X_train, y_train_internal)\n",
    "pred_internal = rm.predict(preprocessed_main_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [0, 307]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-362-45c5f474797f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_internal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_internal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \"\"\"\n\u001b[1;32m    238\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 239\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m~/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [0, 307]"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.mean_squared_error(y_test_internal, pred_internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = []\n",
    "models_ = {}\n",
    "def different_models(df):\n",
    "    groups = df.groupby('Essayset')\n",
    "    for name, group in groups:\n",
    "        multi_datasets[name] = group\n",
    "    pp = []\n",
    "    models_ = {}\n",
    "    for k in multi_datasets:\n",
    "        print(k)\n",
    "        single_df = multi_datasets[k]\n",
    "        single_df.reset_index(inplace=True)\n",
    "        single_df.dropna(axis=0,inplace=True)\n",
    "        \n",
    "        single_df['candi_score'] = single_df[['score_1','score_2' ,'score_3' ,'score_4' ,'score_5']].mean(axis=1)\n",
    "        single_df['candi_score'] = list(map(lambda x : round(x),single_df['candi_score']))\n",
    "        single_df.drop(['score_1','score_2' ,'score_3' ,'score_4' ,'score_5','ID','index'],inplace=True,axis=1)\n",
    "\n",
    "        single_df['kitna_aacha']=single_df['candi_score']\n",
    "        \n",
    "        single_df.drop(['min_score','max_score','Essayset','candi_score'],inplace=True,axis=1)\n",
    "        \n",
    "        all_text  = []\n",
    "        single_df['EssayText']=single_df['EssayText'].apply(preprocess_data)\n",
    "        all_text = list(single_df['EssayText'])\n",
    "        \n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        tfidf = TfidfVectorizer(sublinear_tf=True,use_idf=True, min_df=20, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "        tfidf.fit(all_text)\n",
    "        \n",
    "        features = tfidf.transform(single_df['EssayText'])\n",
    "        \n",
    "        new_tfidf_features = pd.DataFrame(features.toarray())\n",
    "        new_tfidf_features['clarity'] = single_df['clarity']\n",
    "        new_tfidf_features['coherent'] = single_df['coherent']\n",
    "        new_tfidf_features['kitna_aacha'] = single_df['kitna_aacha']\n",
    "        \n",
    "        new_tfidf_features['clarity']=new_tfidf_features['clarity'].fillna(new_tfidf_features['clarity'].mode()[0])\n",
    "        new_tfidf_features['coherent']=new_tfidf_features['coherent'].fillna(new_tfidf_features['coherent'].mode()[0])\n",
    "\n",
    "        new_tfidf_features.dropna(axis=0,inplace=True)\n",
    "        \n",
    "        all_preprocessed_single_q_data =  pd.get_dummies(new_tfidf_features,columns=['clarity' ,'coherent'])\n",
    "        \n",
    "        y_train = (all_preprocessed_single_q_data['kitna_aacha'])\n",
    "        x_train = all_preprocessed_single_q_data.drop(['kitna_aacha'],axis =1)\n",
    "        \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        X_train, X_test, y_train_internal, y_test_internal = train_test_split(x_train,y_train ,test_size =.1)\n",
    "        \n",
    "        # Import the model we are using\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "        # Instantiate model with 1000 decision trees\n",
    "        rf = RandomForestClassifier()\n",
    "\n",
    "        # Train the model on training data\n",
    "        rm = rf.fit(X_train, y_train_internal)\n",
    "        pred_internal = rm.predict(X_test)\n",
    "        \n",
    "        from sklearn import metrics\n",
    "        pp.append(metrics.accuracy_score(y_test_internal, pred_internal))\n",
    "        models_[k] = rf\n",
    "        \n",
    "    return ((pp,models_))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "multi_datasets = {}\n",
    "\n",
    "a,b = different_models(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6824935480419513"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_embedding import BertEmbedding\n",
    "\n",
    "bert_abstract = \"\"\"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers.\n",
    " Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers.\n",
    " As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. \n",
    "BERT is conceptually simple and empirically powerful. \n",
    "It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7 (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5% absolute improvement), outperforming human performance by 2.0%.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bert_abstract.split('\\n')\n",
    "bert_embedding = BertEmbedding()\n",
    "result = bert_embedding(sentences,'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers.',\n",
       " ' Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers.',\n",
       " ' As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. ',\n",
       " 'BERT is conceptually simple and empirically powerful. ',\n",
       " 'It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4% (7.6% absolute improvement), MultiNLI accuracy to 86.7 (5.6% absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5% absolute improvement), outperforming human performance by 2.0%.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result[1][0])\n",
    "sen_vec = []\n",
    "for single_sen,all_word_vec in result:\n",
    "    comlete_sen_vector = np.array(all_word_vec).mean(axis =0)\n",
    "    sen_vec.append((single_sen,comlete_sen_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sen_vec[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "comlete_sen_vector = np.array(result[0][1]).mean(axis =0)\n",
    "len(comlete_sen_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.83167362e-01,  5.98037302e-01,  3.33789326e-02, -6.20065510e-01,\n",
       "        1.85064733e-01, -5.74877203e-01,  2.52220005e-01, -1.95262954e-02,\n",
       "        3.05282533e-01, -3.45093995e-01, -6.90376401e-01,  4.64573614e-02,\n",
       "       -5.02824366e-01,  3.89240310e-02, -8.15680474e-02,  5.61777830e-01,\n",
       "       -3.94920826e-01, -4.24305767e-01,  7.19363391e-02,  4.78396654e-01,\n",
       "        1.22789077e-01,  4.31831539e-01, -7.77603149e-01,  3.69261771e-01,\n",
       "        6.10460699e-01, -1.27367902e+00,  1.01201904e+00, -1.95420161e-02,\n",
       "       -1.89690247e-01,  1.87784255e-01, -2.26875678e-01,  8.03991854e-02,\n",
       "        1.86895803e-02, -7.84316361e-02, -4.00059730e-01,  7.59272039e-01,\n",
       "        5.80961823e-01, -1.64119095e-01, -4.28889811e-01,  4.24854219e-01,\n",
       "       -1.17986172e-01, -4.35561955e-01,  6.06887698e-01,  5.70732296e-01,\n",
       "        1.35500774e-01, -1.03446770e+00,  4.34642613e-01,  7.36153424e-02,\n",
       "        1.23390570e-01, -1.01948641e-01, -1.02304471e+00,  2.02407390e-01,\n",
       "        2.50787467e-01,  2.69107193e-01, -8.90793800e-02,  1.85123235e-01,\n",
       "        1.12771618e+00, -6.21062458e-01,  2.50891626e-01,  3.47955108e-01,\n",
       "        2.06170052e-01, -3.99790466e-01, -1.43650949e-01, -6.99152648e-01,\n",
       "       -3.21512371e-02,  2.74670362e-01, -1.30505189e-01, -2.31607795e-01,\n",
       "       -6.70550823e-01,  1.65730789e-01, -5.53879678e-01, -3.32409352e-01,\n",
       "       -1.51969767e+00, -2.19421104e-01, -5.73499799e-01,  5.46891809e-01,\n",
       "       -5.65355346e-02, -3.96672279e-01, -1.60447121e-01, -5.80599666e-01,\n",
       "       -7.11721063e-01,  7.98504353e-01, -4.12179589e-01,  4.14625108e-01,\n",
       "       -1.99803650e-01,  1.89002156e-01,  2.32255548e-01,  7.41657138e-01,\n",
       "       -6.46718979e-01,  1.22438431e+00, -7.03669131e-01,  6.57660738e-02,\n",
       "        8.08837235e-01,  5.19033849e-01,  3.71187985e-01,  5.17451465e-01,\n",
       "        2.24402159e-01, -9.49143246e-02,  3.12035471e-01, -8.56067240e-02,\n",
       "        4.81371641e-01, -1.80946678e-01, -6.49406075e-01, -2.58861780e-01,\n",
       "        5.67961752e-01, -4.90430355e-01, -8.11612830e-02,  5.30686736e-01,\n",
       "        3.64832319e-02,  3.73499453e-01,  4.95660782e-01, -7.58248642e-02,\n",
       "       -5.80418948e-03, -2.55822480e-01, -1.14545918e+00, -1.14959426e-01,\n",
       "        4.31873411e-01, -9.44099307e-01, -2.05864590e-02,  9.74191353e-02,\n",
       "       -2.24102795e-01,  2.33139321e-01,  1.88986510e-01,  1.21051013e+00,\n",
       "       -4.76510115e-02,  4.75158244e-01, -2.46304691e-01,  1.18212116e+00,\n",
       "        1.78397536e-01, -6.07262135e-01,  7.56276213e-03, -1.83477983e-01,\n",
       "        9.08903539e-01,  2.88813770e-01,  1.55352965e-01, -5.95271885e-01,\n",
       "        1.84948832e-01, -1.99326858e-01, -2.76443273e-01, -6.43805742e-01,\n",
       "        2.10777849e-01,  4.66953874e-01,  1.23339927e+00, -4.15112644e-01,\n",
       "       -3.34929049e-01,  4.47359651e-01, -4.11149800e-01, -3.17249745e-01,\n",
       "       -3.16831797e-01,  8.29738200e-01, -2.51466334e-01,  1.12692368e+00,\n",
       "       -8.02355647e-01,  3.65303397e-01, -9.29144695e-02,  5.42137921e-01,\n",
       "       -7.68940866e-01,  4.18628633e-01, -5.12275577e-01,  1.23811096e-01,\n",
       "        4.77575511e-01, -4.04262185e-01, -7.72842884e-01, -6.04157567e-01,\n",
       "       -3.22836228e-02, -6.21104181e-01,  5.23498833e-01,  4.89466697e-01,\n",
       "        5.05987704e-01, -2.19669893e-01, -1.51313946e-01,  4.23899293e-02,\n",
       "        6.23341799e-01, -2.75840722e-02,  3.05008173e-01,  4.34284180e-01,\n",
       "        2.29123056e-01,  6.00144386e-01,  4.68512140e-02,  3.80280912e-01,\n",
       "       -2.80210972e-01,  2.31791303e-01,  4.78288710e-01, -4.81812626e-01,\n",
       "        1.78750500e-01,  5.11572480e-01, -2.22916409e-01, -1.39279038e-01,\n",
       "        3.75385135e-01,  4.16961685e-02, -8.48234355e-01,  8.20387065e-01,\n",
       "       -9.79705811e-01, -3.31873149e-01,  4.57820743e-01, -6.83259785e-01,\n",
       "        3.72146629e-03,  2.66345114e-01, -8.33328187e-01, -3.08329821e-01,\n",
       "        1.91477954e-01,  2.64191896e-01,  4.02934074e-01, -2.86864996e-01,\n",
       "       -5.68174347e-02, -7.80206084e-01, -2.13840455e-01, -3.28224778e-01,\n",
       "       -5.05082130e-01,  3.90724123e-01, -9.93316591e-01,  5.27615964e-01,\n",
       "        4.30444002e-01, -8.81163776e-01,  6.32778823e-01,  5.18559992e-01,\n",
       "        1.96617365e-01, -4.46186393e-01, -3.87697041e-01,  5.45343578e-01,\n",
       "       -4.19430882e-02, -1.83584362e-01, -1.12997842e+00, -1.54514667e-02,\n",
       "        4.03770328e-01,  1.13754797e+00,  6.44498989e-02,  2.07527518e-01,\n",
       "        4.31485742e-01,  3.00877512e-01,  1.82813048e-01, -6.15506709e-01,\n",
       "        3.50131065e-01,  3.91877234e-01,  2.74098776e-02,  3.41248423e-01,\n",
       "       -4.14833814e-01,  1.62109286e-01,  2.95064718e-01,  4.33630645e-01,\n",
       "       -2.69450128e-01,  2.71501273e-01,  4.98920798e-01, -2.49121696e-01,\n",
       "        6.08475097e-02, -8.37368429e-01, -5.00782430e-01,  1.16130784e-01,\n",
       "       -3.40570509e-01, -7.72045314e-01, -4.76743788e-01, -5.16671300e-01,\n",
       "       -3.18265975e-01, -6.42553866e-01, -2.97045320e-01, -2.34816559e-02,\n",
       "       -4.29980218e-01, -4.32135947e-02,  5.31280100e-01,  8.34366560e-01,\n",
       "        4.57956105e-01,  4.35827076e-02,  3.22618991e-01,  1.15323591e+00,\n",
       "       -6.54370427e-01, -3.85003805e-01, -4.16147113e-02,  7.21789598e-01,\n",
       "        4.48274791e-01, -4.20790195e-01,  5.19011021e-01,  2.21541468e-02,\n",
       "       -9.66273472e-02,  2.69561529e-01, -8.15994978e-01, -3.27690512e-01,\n",
       "       -2.81217918e-02, -4.54311252e-01, -1.64136440e-01, -4.42585677e-01,\n",
       "       -4.29304838e-01,  7.45648801e-01, -5.80390275e-01,  2.32419938e-01,\n",
       "       -3.85081559e-01,  2.59715557e-01, -6.33415759e-01, -7.74899840e-01,\n",
       "        1.81362540e-01, -1.13669550e+00, -1.08906567e-01, -6.88820481e-02,\n",
       "       -6.33087039e-01, -6.84662685e-02,  2.26628687e-03,  4.16015327e-01,\n",
       "        2.35095084e-01, -1.83566660e-01, -4.00265455e-01, -6.84352160e-01,\n",
       "        4.24981445e-01, -5.21874428e-01, -7.24935770e-01,  5.89385271e-01,\n",
       "       -8.72199893e-01, -1.37328833e-01, -3.68211746e-01, -9.40445244e-01,\n",
       "       -4.46116924e+00,  5.85126698e-01, -4.40615594e-01, -1.70248225e-01,\n",
       "        2.72135615e-01,  3.79841417e-01, -3.75571012e-01, -2.27546230e-01,\n",
       "       -6.46847486e-02,  4.72604454e-01,  1.82170495e-01, -4.23950493e-01,\n",
       "       -2.82367975e-01,  4.77632105e-01,  3.02469790e-01,  5.30286074e-01,\n",
       "       -3.64512354e-02, -4.13873434e-01,  2.20126629e-01,  3.09851766e-01,\n",
       "       -7.16197491e-03, -2.59484887e-01,  3.53451043e-01, -6.18557394e-01,\n",
       "        5.77588916e-01,  3.07531238e-01, -5.83814085e-01,  1.61430031e-01,\n",
       "       -8.80703330e-02, -4.87741888e-01,  8.54070425e-01, -4.04816061e-01,\n",
       "        2.30074540e-01, -5.79439223e-01, -5.72304845e-01,  5.82608581e-01,\n",
       "       -2.09547222e-01, -8.29216182e-01,  5.04822731e-01, -7.44213641e-01,\n",
       "       -7.51611650e-01,  7.11117089e-01,  6.69556379e-01, -8.25829208e-01,\n",
       "        4.03110117e-01, -4.27541673e-01, -2.51023710e-01,  2.21504256e-01,\n",
       "        3.62938792e-01,  9.15510297e-01, -9.98829782e-01,  2.74802923e-01,\n",
       "        6.63776934e-01,  6.76014498e-02, -7.43415415e-01, -6.14640176e-01,\n",
       "        4.71284330e-01,  6.37363791e-01, -1.62958995e-01, -3.52068990e-01,\n",
       "        3.74181211e-01, -1.37516171e-01, -7.88609862e-01, -1.68978184e-01,\n",
       "       -4.98002052e-01, -8.41860056e-01, -2.65801132e-01, -5.73227108e-01,\n",
       "       -3.96187574e-01, -1.81940556e-01, -9.07379568e-01,  4.59357679e-01,\n",
       "       -5.62823474e-01, -8.57111633e-01,  1.75090790e-01, -6.54275656e-01,\n",
       "       -3.48231792e-01,  3.34778607e-01,  1.87499598e-01, -7.44583309e-01,\n",
       "        1.94052190e-01, -1.49136388e+00, -5.12313366e-01, -2.44314581e-01,\n",
       "       -7.56738484e-02, -2.92914927e-01,  1.17764518e-01, -4.52760547e-01,\n",
       "       -1.54427871e-01, -9.53132287e-02,  1.87609047e-01,  7.30225682e-01,\n",
       "       -3.63292620e-02,  6.85355067e-01, -3.35930079e-01, -2.21351981e-01,\n",
       "        4.23405319e-01,  1.16004817e-01,  4.86707211e-01, -2.60196388e-01,\n",
       "        9.94753242e-01, -2.55162977e-02, -5.78680515e-01,  1.15046263e-01,\n",
       "        3.10301512e-01, -8.83427501e-01, -4.85645086e-01,  3.98556292e-01,\n",
       "        1.07198358e+00,  7.71377683e-01, -5.71116209e-01, -1.63495183e-01,\n",
       "        6.78869635e-02, -8.27873468e-01,  7.14219138e-02,  1.39444113e+00,\n",
       "       -1.88485444e-01,  1.92453891e-01,  7.85571337e-01, -7.83578336e-01,\n",
       "        8.59580413e-02,  8.40600848e-01, -7.33109415e-01,  1.76249519e-01,\n",
       "        4.45342958e-01, -3.88500422e-01, -5.04953712e-02, -3.00280064e-01,\n",
       "        2.77300179e-01,  2.69767623e-02, -5.79135239e-01, -7.25716472e-01,\n",
       "       -7.14993656e-01,  2.36229494e-01,  1.71433240e-01, -5.05446732e-01,\n",
       "       -3.75034988e-01,  1.83213457e-01,  2.16499746e-01,  1.08042896e-01,\n",
       "        7.09023327e-02,  4.60300446e-01, -4.28410023e-01, -1.12914658e+00,\n",
       "        6.62615478e-01,  3.72905403e-01,  1.09084308e+00,  3.02503049e-01,\n",
       "        6.28438219e-02, -3.54779780e-01, -2.83860564e-01, -7.66450226e-01,\n",
       "        2.43035123e-01, -7.12615073e-01, -5.01505792e-01, -6.66796029e-01,\n",
       "        5.60788095e-01,  3.41681898e-01,  7.47721851e-01, -7.36899436e-01,\n",
       "        6.18750811e-01,  2.63046741e-01,  5.48864961e-01,  3.98986280e-01,\n",
       "       -5.72857916e-01,  9.44258332e-01,  3.33059132e-01, -2.86788456e-02,\n",
       "       -4.83904719e-01, -6.48796141e-01,  2.40053400e-01,  1.38375461e-01,\n",
       "        5.38388267e-02, -2.13663757e-01,  7.38273740e-01,  1.65373430e-01,\n",
       "       -2.48895586e-02,  7.58088678e-02,  5.39858758e-01,  3.64486814e-01,\n",
       "        6.12602711e-01, -7.66405404e-01, -8.11637938e-03,  6.98868394e-01,\n",
       "        3.67248237e-01,  3.10920686e-01, -1.24437183e-01,  5.97264230e-01,\n",
       "       -5.74499011e-01,  1.74266845e-01, -2.84465194e-01,  7.97002017e-02,\n",
       "       -4.00089085e-01,  4.08470839e-01, -8.86565447e-01, -3.57899696e-01,\n",
       "        3.35419416e-01,  5.04145086e-01,  6.17069244e-01, -6.12319231e-01,\n",
       "        5.34681141e-01, -2.15222895e-01,  9.62476060e-02,  3.72229069e-01,\n",
       "        7.69908309e-01,  1.77322268e-01, -3.59895408e-01, -2.70461500e-01,\n",
       "        8.56139511e-02, -2.32994020e-01,  2.08100885e-01, -2.77802646e-02,\n",
       "       -5.57726212e-02, -6.78331256e-01, -2.72259153e-02,  3.22436094e-02,\n",
       "        4.11273599e-01, -5.14090955e-01, -5.02220273e-01,  2.19619483e-01,\n",
       "        1.87062711e-01,  1.91178992e-02,  3.73270631e-01,  3.30482811e-01,\n",
       "       -5.07029295e-02,  3.16591382e-01, -2.86386162e-01, -1.38904184e-01,\n",
       "       -4.98739094e-01,  1.10621519e-01, -2.28635445e-01, -5.98184824e-01,\n",
       "        8.28517973e-01, -8.37354660e-02, -3.66270185e-01,  5.67792952e-01,\n",
       "       -2.70377070e-01,  1.18358709e-01, -3.63485456e-01, -5.49710035e-01,\n",
       "       -4.56468791e-01,  1.29275844e-01, -2.56337553e-01, -7.72585571e-01,\n",
       "        3.22929710e-01, -4.71148908e-01, -6.21241570e-01,  9.12983000e-01,\n",
       "       -1.46334514e-01,  1.62149131e-01, -3.99939865e-02, -2.78048992e-01,\n",
       "       -5.67034006e-01, -3.44051212e-01,  5.76990366e-01, -1.01171613e+00,\n",
       "       -6.28685772e-01, -7.04605818e-01, -6.41672134e-01,  1.69166580e-01,\n",
       "        7.58742809e-01,  4.08941209e-02, -5.92243850e-01,  1.56211734e-01,\n",
       "        4.71496433e-02, -3.04323584e-02, -7.13872015e-02,  1.32132575e-01,\n",
       "        4.46497560e-01, -4.31910872e-01, -1.03692400e+00, -4.20525193e-01,\n",
       "        6.63863301e-01,  9.54251736e-03,  1.02469712e-01, -4.31305170e-01,\n",
       "       -2.53131483e-02, -5.00747144e-01,  3.50287706e-01,  5.91545328e-02,\n",
       "       -8.74647647e-02, -1.32154748e-01, -3.33576232e-01, -8.03709775e-02,\n",
       "        4.78972971e-01,  7.09997654e-01, -1.79199934e-01,  6.71544135e-01,\n",
       "        2.43598267e-01, -2.53345408e-02, -2.32102096e-01,  2.20954210e-01,\n",
       "       -2.61112630e-01,  3.84346187e-01, -2.83700228e-01,  1.07691920e+00,\n",
       "        3.18246961e-01, -5.07007122e-01, -9.89744067e-02,  4.25150506e-02,\n",
       "        4.77125049e-01,  9.23735976e-01,  3.78375202e-01,  6.12890124e-01,\n",
       "       -3.29854280e-01, -1.40114442e-01,  4.81749624e-01,  4.55193579e-01,\n",
       "        2.92972118e-01,  8.48007977e-01,  4.74981368e-01, -5.30830681e-01,\n",
       "        3.22710335e-01,  6.80292964e-01, -8.60642970e-01,  4.24487293e-01,\n",
       "        4.26642716e-01,  9.83633101e-03,  3.97075921e-01,  1.98780164e-01,\n",
       "       -6.76693439e-01, -2.23183215e-01,  1.01919129e-01, -3.89925539e-01,\n",
       "       -3.64185929e-01, -1.62929520e-01,  2.58686036e-01,  3.65126133e-01,\n",
       "       -6.48148358e-01, -3.51836234e-01,  3.07212859e-01,  6.32651806e-01,\n",
       "        7.53418282e-02,  1.05198957e-01, -5.20097911e-01, -8.80612016e-01,\n",
       "        1.03530586e+00, -3.33869457e-01,  4.36681926e-01, -1.14266418e-01,\n",
       "        8.12466979e-01,  1.88197643e-01,  4.29898381e-01,  4.72887456e-01,\n",
       "        3.90130013e-01, -8.78390610e-01,  1.91273123e-01,  6.56720161e-01,\n",
       "        5.73536813e-01,  6.88193202e-01,  5.05890131e-01,  8.91235471e-02,\n",
       "        2.34230012e-01, -2.73780115e-02,  5.59999764e-01,  1.75090536e-01,\n",
       "        1.55266702e-01,  4.68521684e-01,  1.03275251e+00,  6.85274184e-01,\n",
       "       -7.18340054e-02,  6.48460746e-01,  1.87276840e-01, -1.01449537e+00,\n",
       "        2.71869302e-01,  4.86137807e-01,  2.14452580e-01, -2.54508466e-01,\n",
       "       -6.92407608e-01, -8.23259413e-01,  4.62992817e-01, -3.00272495e-01,\n",
       "       -2.65043467e-01,  6.09781183e-02,  4.16114807e-01, -1.61312550e-01,\n",
       "       -1.48698449e-01, -7.04037607e-01, -5.90218186e-01, -2.68357337e-01,\n",
       "        2.13650279e-02, -2.73098014e-02, -6.60780311e-01, -7.31487155e-01,\n",
       "       -1.83146402e-01, -5.85047901e-01,  4.92376313e-02, -2.51456797e-01,\n",
       "        5.59790313e-01, -1.14046119e-01, -5.38202465e-01,  1.46782696e-02,\n",
       "        7.29304969e-01, -4.59494054e-01,  1.68328255e-01,  3.18599567e-02,\n",
       "       -3.12566400e-01,  9.26717222e-01,  3.94680798e-01, -5.22200167e-01,\n",
       "       -2.61936486e-01, -3.06731224e-01, -5.02580941e-01,  3.92676085e-01,\n",
       "        1.11786924e-01,  1.18271315e+00,  7.14464366e-01,  3.47880393e-01,\n",
       "        2.39998430e-01, -3.51651073e-01,  8.96890402e-01,  8.07586849e-01,\n",
       "       -8.57821584e-01, -5.07724404e-01,  5.60291827e-01,  1.54209778e-01,\n",
       "        3.40166181e-01,  3.04278582e-01, -3.92851800e-01, -1.56674773e-01,\n",
       "       -6.67176664e-01,  1.51639387e-01,  7.62817919e-01, -6.21217132e-01,\n",
       "       -2.02212974e-01,  2.38848105e-01,  3.07656556e-01,  3.00812334e-01,\n",
       "       -1.90936282e-01,  1.10883661e-01,  5.31493962e-01,  5.81277311e-01,\n",
       "       -2.66693383e-02,  6.43515825e-01,  9.73886475e-02, -4.36422944e-01,\n",
       "        2.40774021e-01, -1.57769114e-01,  5.03333032e-01,  5.09071887e-01,\n",
       "       -3.44055176e-01,  4.86850560e-01, -1.47115007e-01,  4.58277583e-01,\n",
       "        3.65329921e-01,  5.06382167e-01, -5.41176200e-01, -5.59906304e-01,\n",
       "       -5.11654496e-01,  2.57725805e-01, -2.53262013e-01,  5.97246826e-01,\n",
       "       -6.89621568e-01, -1.11968994e-01, -2.56145149e-01,  1.58199772e-01,\n",
       "        1.53026327e-01,  8.64990205e-02, -1.95781767e-01, -5.06883487e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(result[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(bert_embedding,sentences):\n",
    "    #sentences \n",
    "    result = bert_embedding(sentences,'sum')\n",
    "    sen_vec = []\n",
    "    for single_sen,all_word_vec in result:\n",
    "        comlete_sen_vector = np.array(all_word_vec).mean(axis =0)\n",
    "        sen_vec.append(comlete_sen_vector)\n",
    "         \n",
    "            \n",
    "    return sen_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "/home/prashant/miniconda2/envs/p3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "pp = get_vector(bert_embedding ,  ['a',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Essayset  min_score  max_score  score_1  score_2  score_3  score_4  \\\n",
      "0   1       1.0          0          3        1        1      1.0      1.0   \n",
      "1   2       1.0          0          3        1        1      NaN      1.5   \n",
      "2   3       1.0          0          3        1        1      1.0      1.0   \n",
      "3   4       1.0          0          3        0        0      0.0      0.0   \n",
      "4   5       1.0          0          3        2        2      2.0      2.5   \n",
      "\n",
      "   score_5        clarity       coherent  \\\n",
      "0      1.0        average          worst   \n",
      "1      1.0      excellent          worst   \n",
      "2      1.5          worst  above_average   \n",
      "3      1.0          worst          worst   \n",
      "4      1.0  above_average          worst   \n",
      "\n",
      "                                           EssayText  \n",
      "0  Some additional information that we would need...  \n",
      "1  After reading the expirement, I realized that ...  \n",
      "2  What you need is more trials, a control set up...  \n",
      "3  The student should list what rock is better an...  \n",
      "4  For the students to be able to make a replicat...  \n",
      "(1657, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1657"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_csv('train_dataset.csv')\n",
    "print(df.head())\n",
    "df = df.loc[df['Essayset'] ==1]\n",
    "print(df.shape)\n",
    "s = list(df['EssayText'])\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = get_vector(bert_embedding,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-1fbf2a777932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_tfidf_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/p3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/p3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   7493\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7494\u001b[0m         \u001b[0;31m# last ditch effort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7495\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7496\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[1;32m   7497\u001b[0m                                dtype=dtype)\n",
      "\u001b[0;32m~/miniconda2/envs/p3/lib/python3.6/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mlmap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "new_tfidf_features = pd.DataFrame(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.209471</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>-0.115139</td>\n",
       "      <td>0.155171</td>\n",
       "      <td>0.477535</td>\n",
       "      <td>-0.195618</td>\n",
       "      <td>-0.013060</td>\n",
       "      <td>0.231690</td>\n",
       "      <td>0.323169</td>\n",
       "      <td>-0.301131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.406724</td>\n",
       "      <td>-0.040973</td>\n",
       "      <td>-0.027652</td>\n",
       "      <td>-0.111346</td>\n",
       "      <td>-0.153751</td>\n",
       "      <td>0.059796</td>\n",
       "      <td>0.271627</td>\n",
       "      <td>-0.166859</td>\n",
       "      <td>0.266631</td>\n",
       "      <td>0.047705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.110659</td>\n",
       "      <td>-0.038571</td>\n",
       "      <td>0.083564</td>\n",
       "      <td>0.122763</td>\n",
       "      <td>0.229474</td>\n",
       "      <td>-0.293610</td>\n",
       "      <td>0.138813</td>\n",
       "      <td>0.316974</td>\n",
       "      <td>0.124054</td>\n",
       "      <td>-0.196293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045047</td>\n",
       "      <td>0.011148</td>\n",
       "      <td>0.041355</td>\n",
       "      <td>-0.202223</td>\n",
       "      <td>-0.124132</td>\n",
       "      <td>-0.032951</td>\n",
       "      <td>0.210262</td>\n",
       "      <td>0.048532</td>\n",
       "      <td>-0.073355</td>\n",
       "      <td>0.153868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.105877</td>\n",
       "      <td>-0.126139</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>0.353253</td>\n",
       "      <td>0.354069</td>\n",
       "      <td>-0.232021</td>\n",
       "      <td>-0.035967</td>\n",
       "      <td>0.070528</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>-0.277295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.259656</td>\n",
       "      <td>-0.303123</td>\n",
       "      <td>-0.236008</td>\n",
       "      <td>-0.048549</td>\n",
       "      <td>-0.055279</td>\n",
       "      <td>0.216803</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>-0.366128</td>\n",
       "      <td>0.102854</td>\n",
       "      <td>0.375488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.306760</td>\n",
       "      <td>-0.072570</td>\n",
       "      <td>-0.030354</td>\n",
       "      <td>-0.015995</td>\n",
       "      <td>0.274578</td>\n",
       "      <td>-0.018717</td>\n",
       "      <td>0.272740</td>\n",
       "      <td>0.152896</td>\n",
       "      <td>0.272880</td>\n",
       "      <td>-0.403173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159280</td>\n",
       "      <td>-0.087001</td>\n",
       "      <td>0.050957</td>\n",
       "      <td>0.070430</td>\n",
       "      <td>-0.106263</td>\n",
       "      <td>0.094872</td>\n",
       "      <td>0.043582</td>\n",
       "      <td>-0.020065</td>\n",
       "      <td>0.508369</td>\n",
       "      <td>0.091591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015524</td>\n",
       "      <td>0.107056</td>\n",
       "      <td>-0.131454</td>\n",
       "      <td>0.036079</td>\n",
       "      <td>0.357085</td>\n",
       "      <td>0.104878</td>\n",
       "      <td>0.202547</td>\n",
       "      <td>0.311471</td>\n",
       "      <td>0.347213</td>\n",
       "      <td>-0.294072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.486928</td>\n",
       "      <td>-0.445874</td>\n",
       "      <td>0.028652</td>\n",
       "      <td>-0.181518</td>\n",
       "      <td>-0.186059</td>\n",
       "      <td>0.195187</td>\n",
       "      <td>0.094222</td>\n",
       "      <td>-0.200974</td>\n",
       "      <td>0.422862</td>\n",
       "      <td>0.386694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.086325</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.049581</td>\n",
       "      <td>0.331226</td>\n",
       "      <td>0.195899</td>\n",
       "      <td>-0.161240</td>\n",
       "      <td>-0.333660</td>\n",
       "      <td>0.332043</td>\n",
       "      <td>-0.124765</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218233</td>\n",
       "      <td>-0.162323</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.259459</td>\n",
       "      <td>-0.218776</td>\n",
       "      <td>-0.109985</td>\n",
       "      <td>0.111837</td>\n",
       "      <td>-0.036943</td>\n",
       "      <td>0.089155</td>\n",
       "      <td>-0.009786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.087262</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>0.010001</td>\n",
       "      <td>0.085915</td>\n",
       "      <td>0.297967</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>0.267242</td>\n",
       "      <td>0.216932</td>\n",
       "      <td>0.238011</td>\n",
       "      <td>-0.373344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372051</td>\n",
       "      <td>-0.061580</td>\n",
       "      <td>0.220201</td>\n",
       "      <td>-0.275639</td>\n",
       "      <td>-0.227072</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.359274</td>\n",
       "      <td>-0.344252</td>\n",
       "      <td>0.250150</td>\n",
       "      <td>0.117292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.125913</td>\n",
       "      <td>-0.294783</td>\n",
       "      <td>0.034882</td>\n",
       "      <td>0.252560</td>\n",
       "      <td>0.392762</td>\n",
       "      <td>-0.150249</td>\n",
       "      <td>0.012134</td>\n",
       "      <td>0.098217</td>\n",
       "      <td>0.112444</td>\n",
       "      <td>-0.382418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113561</td>\n",
       "      <td>-0.075491</td>\n",
       "      <td>0.008705</td>\n",
       "      <td>-0.176691</td>\n",
       "      <td>-0.428926</td>\n",
       "      <td>-0.254321</td>\n",
       "      <td>0.388297</td>\n",
       "      <td>-0.185857</td>\n",
       "      <td>0.239657</td>\n",
       "      <td>-0.030906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.191039</td>\n",
       "      <td>-0.075475</td>\n",
       "      <td>-0.021523</td>\n",
       "      <td>0.143183</td>\n",
       "      <td>0.322996</td>\n",
       "      <td>-0.492606</td>\n",
       "      <td>-0.184364</td>\n",
       "      <td>0.484266</td>\n",
       "      <td>-0.272178</td>\n",
       "      <td>-0.287135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116671</td>\n",
       "      <td>-0.097174</td>\n",
       "      <td>0.232923</td>\n",
       "      <td>-0.392272</td>\n",
       "      <td>-0.257715</td>\n",
       "      <td>-0.263478</td>\n",
       "      <td>-0.079174</td>\n",
       "      <td>0.080497</td>\n",
       "      <td>0.236805</td>\n",
       "      <td>-0.225707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.114660</td>\n",
       "      <td>-0.129702</td>\n",
       "      <td>0.189297</td>\n",
       "      <td>-0.002228</td>\n",
       "      <td>0.332263</td>\n",
       "      <td>-0.325988</td>\n",
       "      <td>0.274241</td>\n",
       "      <td>0.147959</td>\n",
       "      <td>0.345936</td>\n",
       "      <td>-0.199805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062633</td>\n",
       "      <td>0.156715</td>\n",
       "      <td>-0.182623</td>\n",
       "      <td>-0.198911</td>\n",
       "      <td>-0.137349</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.108520</td>\n",
       "      <td>-0.312357</td>\n",
       "      <td>0.231118</td>\n",
       "      <td>0.127369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.158063</td>\n",
       "      <td>-0.046017</td>\n",
       "      <td>0.037953</td>\n",
       "      <td>-0.045892</td>\n",
       "      <td>0.402241</td>\n",
       "      <td>-0.247476</td>\n",
       "      <td>0.382731</td>\n",
       "      <td>0.358171</td>\n",
       "      <td>0.054929</td>\n",
       "      <td>-0.367211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093414</td>\n",
       "      <td>0.090275</td>\n",
       "      <td>0.267203</td>\n",
       "      <td>-0.237173</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>-0.228276</td>\n",
       "      <td>0.198818</td>\n",
       "      <td>-0.045617</td>\n",
       "      <td>0.082915</td>\n",
       "      <td>0.083829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.017336</td>\n",
       "      <td>-0.212728</td>\n",
       "      <td>-0.058866</td>\n",
       "      <td>0.128317</td>\n",
       "      <td>0.458701</td>\n",
       "      <td>-0.227745</td>\n",
       "      <td>0.045674</td>\n",
       "      <td>0.134108</td>\n",
       "      <td>0.190062</td>\n",
       "      <td>-0.312267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237606</td>\n",
       "      <td>0.033079</td>\n",
       "      <td>0.203992</td>\n",
       "      <td>-0.315152</td>\n",
       "      <td>-0.370223</td>\n",
       "      <td>-0.258419</td>\n",
       "      <td>0.258914</td>\n",
       "      <td>-0.205614</td>\n",
       "      <td>0.404592</td>\n",
       "      <td>-0.108580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.178281</td>\n",
       "      <td>-0.265382</td>\n",
       "      <td>0.255352</td>\n",
       "      <td>0.329565</td>\n",
       "      <td>0.609954</td>\n",
       "      <td>-0.174955</td>\n",
       "      <td>0.166275</td>\n",
       "      <td>0.118757</td>\n",
       "      <td>0.036436</td>\n",
       "      <td>-0.291476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174364</td>\n",
       "      <td>0.130891</td>\n",
       "      <td>-0.102295</td>\n",
       "      <td>-0.063202</td>\n",
       "      <td>-0.436743</td>\n",
       "      <td>-0.129528</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>-0.235703</td>\n",
       "      <td>0.291222</td>\n",
       "      <td>0.181057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.132213</td>\n",
       "      <td>-0.390876</td>\n",
       "      <td>-0.363131</td>\n",
       "      <td>-0.083741</td>\n",
       "      <td>0.464973</td>\n",
       "      <td>-0.307907</td>\n",
       "      <td>0.318645</td>\n",
       "      <td>0.538655</td>\n",
       "      <td>0.337443</td>\n",
       "      <td>-0.613057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079516</td>\n",
       "      <td>-0.115987</td>\n",
       "      <td>0.222240</td>\n",
       "      <td>-0.045644</td>\n",
       "      <td>-0.019237</td>\n",
       "      <td>0.232199</td>\n",
       "      <td>0.452438</td>\n",
       "      <td>-0.357158</td>\n",
       "      <td>0.468553</td>\n",
       "      <td>-0.106071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.028340</td>\n",
       "      <td>0.085461</td>\n",
       "      <td>0.050545</td>\n",
       "      <td>0.060784</td>\n",
       "      <td>0.536255</td>\n",
       "      <td>-0.145110</td>\n",
       "      <td>-0.135764</td>\n",
       "      <td>0.555163</td>\n",
       "      <td>0.046966</td>\n",
       "      <td>-0.263132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012180</td>\n",
       "      <td>-0.135883</td>\n",
       "      <td>-0.148727</td>\n",
       "      <td>-0.093363</td>\n",
       "      <td>-0.367104</td>\n",
       "      <td>0.211227</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>-0.203195</td>\n",
       "      <td>0.220710</td>\n",
       "      <td>0.375449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.418620</td>\n",
       "      <td>0.526589</td>\n",
       "      <td>-0.023410</td>\n",
       "      <td>-0.331130</td>\n",
       "      <td>0.078320</td>\n",
       "      <td>-0.520944</td>\n",
       "      <td>0.022741</td>\n",
       "      <td>1.123456</td>\n",
       "      <td>-0.542006</td>\n",
       "      <td>0.232951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132977</td>\n",
       "      <td>-0.035942</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>-0.268821</td>\n",
       "      <td>-0.329891</td>\n",
       "      <td>-0.170559</td>\n",
       "      <td>0.208345</td>\n",
       "      <td>-0.491415</td>\n",
       "      <td>-0.110553</td>\n",
       "      <td>0.006148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.120116</td>\n",
       "      <td>0.027194</td>\n",
       "      <td>0.145966</td>\n",
       "      <td>-0.084733</td>\n",
       "      <td>0.281918</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.255245</td>\n",
       "      <td>0.087583</td>\n",
       "      <td>0.156107</td>\n",
       "      <td>-0.405868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220232</td>\n",
       "      <td>-0.202940</td>\n",
       "      <td>0.237187</td>\n",
       "      <td>-0.403492</td>\n",
       "      <td>-0.355451</td>\n",
       "      <td>-0.181120</td>\n",
       "      <td>0.177935</td>\n",
       "      <td>-0.048403</td>\n",
       "      <td>0.048722</td>\n",
       "      <td>0.356045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.109449</td>\n",
       "      <td>-0.005876</td>\n",
       "      <td>0.101696</td>\n",
       "      <td>-0.007995</td>\n",
       "      <td>0.156524</td>\n",
       "      <td>-0.199592</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>0.333881</td>\n",
       "      <td>0.195976</td>\n",
       "      <td>-0.435123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449158</td>\n",
       "      <td>0.090733</td>\n",
       "      <td>0.223597</td>\n",
       "      <td>-0.322486</td>\n",
       "      <td>-0.397208</td>\n",
       "      <td>-0.059772</td>\n",
       "      <td>0.211373</td>\n",
       "      <td>-0.187711</td>\n",
       "      <td>0.141056</td>\n",
       "      <td>0.025794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.263593</td>\n",
       "      <td>-0.130139</td>\n",
       "      <td>-0.035034</td>\n",
       "      <td>0.031464</td>\n",
       "      <td>0.166088</td>\n",
       "      <td>-0.109743</td>\n",
       "      <td>0.455733</td>\n",
       "      <td>0.532889</td>\n",
       "      <td>0.081759</td>\n",
       "      <td>-0.414516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460686</td>\n",
       "      <td>-0.134049</td>\n",
       "      <td>0.244823</td>\n",
       "      <td>-0.179731</td>\n",
       "      <td>-0.134949</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>-0.105364</td>\n",
       "      <td>-0.393908</td>\n",
       "      <td>0.340045</td>\n",
       "      <td>0.096414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.193096</td>\n",
       "      <td>0.212816</td>\n",
       "      <td>-0.004589</td>\n",
       "      <td>0.123028</td>\n",
       "      <td>-0.004695</td>\n",
       "      <td>-0.067322</td>\n",
       "      <td>0.235207</td>\n",
       "      <td>0.248815</td>\n",
       "      <td>-0.011291</td>\n",
       "      <td>-0.162872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.454678</td>\n",
       "      <td>0.040477</td>\n",
       "      <td>0.110328</td>\n",
       "      <td>-0.057601</td>\n",
       "      <td>-0.126198</td>\n",
       "      <td>-0.103152</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>-0.316052</td>\n",
       "      <td>0.267714</td>\n",
       "      <td>0.053662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.064434</td>\n",
       "      <td>0.069352</td>\n",
       "      <td>-0.036050</td>\n",
       "      <td>0.074794</td>\n",
       "      <td>0.168766</td>\n",
       "      <td>0.078829</td>\n",
       "      <td>-0.109721</td>\n",
       "      <td>0.048042</td>\n",
       "      <td>0.202647</td>\n",
       "      <td>-0.474558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181724</td>\n",
       "      <td>-0.215792</td>\n",
       "      <td>-0.060156</td>\n",
       "      <td>-0.224164</td>\n",
       "      <td>-0.135071</td>\n",
       "      <td>-0.056238</td>\n",
       "      <td>-0.208722</td>\n",
       "      <td>0.083292</td>\n",
       "      <td>0.301749</td>\n",
       "      <td>0.227606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.046450</td>\n",
       "      <td>0.068138</td>\n",
       "      <td>0.141293</td>\n",
       "      <td>0.090107</td>\n",
       "      <td>0.089019</td>\n",
       "      <td>-0.035811</td>\n",
       "      <td>0.129994</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.174285</td>\n",
       "      <td>-0.176147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217916</td>\n",
       "      <td>-0.019270</td>\n",
       "      <td>0.121075</td>\n",
       "      <td>-0.169939</td>\n",
       "      <td>-0.289092</td>\n",
       "      <td>-0.301424</td>\n",
       "      <td>0.091092</td>\n",
       "      <td>-0.086131</td>\n",
       "      <td>0.274272</td>\n",
       "      <td>0.136629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.510245</td>\n",
       "      <td>-0.098832</td>\n",
       "      <td>-0.089534</td>\n",
       "      <td>0.269089</td>\n",
       "      <td>0.454192</td>\n",
       "      <td>-0.082611</td>\n",
       "      <td>0.215839</td>\n",
       "      <td>0.172812</td>\n",
       "      <td>0.141612</td>\n",
       "      <td>-0.159059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083163</td>\n",
       "      <td>0.069656</td>\n",
       "      <td>-0.124532</td>\n",
       "      <td>-0.295635</td>\n",
       "      <td>-0.422188</td>\n",
       "      <td>-0.076995</td>\n",
       "      <td>-0.215519</td>\n",
       "      <td>-0.289105</td>\n",
       "      <td>0.380795</td>\n",
       "      <td>0.048172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.054064</td>\n",
       "      <td>0.034140</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.171971</td>\n",
       "      <td>0.363994</td>\n",
       "      <td>-0.003656</td>\n",
       "      <td>0.044114</td>\n",
       "      <td>0.082386</td>\n",
       "      <td>0.107704</td>\n",
       "      <td>-0.152961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412349</td>\n",
       "      <td>-0.103072</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>-0.157215</td>\n",
       "      <td>-0.006288</td>\n",
       "      <td>0.103977</td>\n",
       "      <td>0.203302</td>\n",
       "      <td>-0.271420</td>\n",
       "      <td>0.141007</td>\n",
       "      <td>0.117431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.085210</td>\n",
       "      <td>0.154348</td>\n",
       "      <td>-0.304565</td>\n",
       "      <td>0.135836</td>\n",
       "      <td>0.369819</td>\n",
       "      <td>-0.094063</td>\n",
       "      <td>0.009904</td>\n",
       "      <td>0.525410</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>-0.227735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442147</td>\n",
       "      <td>-0.212807</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>-0.186856</td>\n",
       "      <td>-0.167920</td>\n",
       "      <td>0.110090</td>\n",
       "      <td>0.143938</td>\n",
       "      <td>-0.115060</td>\n",
       "      <td>0.093233</td>\n",
       "      <td>-0.117235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.034947</td>\n",
       "      <td>0.265486</td>\n",
       "      <td>-0.164463</td>\n",
       "      <td>-0.164292</td>\n",
       "      <td>0.010458</td>\n",
       "      <td>0.113705</td>\n",
       "      <td>0.299325</td>\n",
       "      <td>0.580719</td>\n",
       "      <td>0.055595</td>\n",
       "      <td>0.164588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242584</td>\n",
       "      <td>-0.362824</td>\n",
       "      <td>0.092887</td>\n",
       "      <td>-0.116698</td>\n",
       "      <td>-0.127281</td>\n",
       "      <td>-0.169401</td>\n",
       "      <td>0.059915</td>\n",
       "      <td>-0.295112</td>\n",
       "      <td>0.115782</td>\n",
       "      <td>0.055739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.275341</td>\n",
       "      <td>0.340005</td>\n",
       "      <td>-0.141785</td>\n",
       "      <td>0.116333</td>\n",
       "      <td>0.184926</td>\n",
       "      <td>0.101826</td>\n",
       "      <td>0.324654</td>\n",
       "      <td>0.576921</td>\n",
       "      <td>-0.131334</td>\n",
       "      <td>-0.192944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071797</td>\n",
       "      <td>-0.331615</td>\n",
       "      <td>-0.084602</td>\n",
       "      <td>-0.160845</td>\n",
       "      <td>-0.164488</td>\n",
       "      <td>0.037604</td>\n",
       "      <td>-0.091446</td>\n",
       "      <td>-0.153977</td>\n",
       "      <td>0.335259</td>\n",
       "      <td>-0.146477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.008988</td>\n",
       "      <td>0.076374</td>\n",
       "      <td>0.435919</td>\n",
       "      <td>0.166848</td>\n",
       "      <td>0.487784</td>\n",
       "      <td>0.223516</td>\n",
       "      <td>0.109159</td>\n",
       "      <td>0.115567</td>\n",
       "      <td>-0.224231</td>\n",
       "      <td>-0.067205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190269</td>\n",
       "      <td>0.109330</td>\n",
       "      <td>-0.008540</td>\n",
       "      <td>-0.029086</td>\n",
       "      <td>-0.225280</td>\n",
       "      <td>-0.115866</td>\n",
       "      <td>-0.213113</td>\n",
       "      <td>-0.181627</td>\n",
       "      <td>0.340574</td>\n",
       "      <td>0.186039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.203956</td>\n",
       "      <td>-0.108057</td>\n",
       "      <td>-0.284082</td>\n",
       "      <td>-0.029245</td>\n",
       "      <td>0.292239</td>\n",
       "      <td>-0.061983</td>\n",
       "      <td>0.131715</td>\n",
       "      <td>0.324962</td>\n",
       "      <td>0.185225</td>\n",
       "      <td>-0.352440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174547</td>\n",
       "      <td>-0.117017</td>\n",
       "      <td>0.109617</td>\n",
       "      <td>-0.115091</td>\n",
       "      <td>-0.257063</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.071385</td>\n",
       "      <td>-0.388143</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.120843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.295167</td>\n",
       "      <td>-0.226582</td>\n",
       "      <td>-0.218571</td>\n",
       "      <td>-0.093558</td>\n",
       "      <td>0.251631</td>\n",
       "      <td>-0.228139</td>\n",
       "      <td>-0.019088</td>\n",
       "      <td>0.103263</td>\n",
       "      <td>0.198132</td>\n",
       "      <td>-0.326215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009350</td>\n",
       "      <td>-0.174707</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>-0.137720</td>\n",
       "      <td>-0.218207</td>\n",
       "      <td>-0.111663</td>\n",
       "      <td>0.081920</td>\n",
       "      <td>-0.166327</td>\n",
       "      <td>0.264691</td>\n",
       "      <td>0.048727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0.035921</td>\n",
       "      <td>-0.119755</td>\n",
       "      <td>-0.290755</td>\n",
       "      <td>0.223579</td>\n",
       "      <td>0.319290</td>\n",
       "      <td>-0.259933</td>\n",
       "      <td>0.266914</td>\n",
       "      <td>0.300501</td>\n",
       "      <td>0.392987</td>\n",
       "      <td>-0.467993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237950</td>\n",
       "      <td>-0.086248</td>\n",
       "      <td>0.103396</td>\n",
       "      <td>-0.030517</td>\n",
       "      <td>-0.372285</td>\n",
       "      <td>0.036003</td>\n",
       "      <td>0.427573</td>\n",
       "      <td>-0.407655</td>\n",
       "      <td>0.251529</td>\n",
       "      <td>0.136620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>0.041996</td>\n",
       "      <td>-0.002779</td>\n",
       "      <td>-0.331530</td>\n",
       "      <td>0.053845</td>\n",
       "      <td>0.624551</td>\n",
       "      <td>-0.149763</td>\n",
       "      <td>0.097528</td>\n",
       "      <td>0.368561</td>\n",
       "      <td>0.332120</td>\n",
       "      <td>-0.262467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460937</td>\n",
       "      <td>-0.346799</td>\n",
       "      <td>-0.058143</td>\n",
       "      <td>-0.118170</td>\n",
       "      <td>-0.049363</td>\n",
       "      <td>-0.171821</td>\n",
       "      <td>0.296658</td>\n",
       "      <td>-0.348678</td>\n",
       "      <td>0.240472</td>\n",
       "      <td>0.022283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>0.027175</td>\n",
       "      <td>-0.027428</td>\n",
       "      <td>0.370443</td>\n",
       "      <td>0.163214</td>\n",
       "      <td>0.382040</td>\n",
       "      <td>-0.237298</td>\n",
       "      <td>0.170825</td>\n",
       "      <td>0.055210</td>\n",
       "      <td>0.258049</td>\n",
       "      <td>-0.301305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043902</td>\n",
       "      <td>0.185778</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>-0.354997</td>\n",
       "      <td>-0.215179</td>\n",
       "      <td>0.044193</td>\n",
       "      <td>-0.010451</td>\n",
       "      <td>-0.432368</td>\n",
       "      <td>0.170202</td>\n",
       "      <td>-0.072244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>0.291832</td>\n",
       "      <td>-0.098329</td>\n",
       "      <td>-0.170266</td>\n",
       "      <td>0.155142</td>\n",
       "      <td>0.119299</td>\n",
       "      <td>-0.268513</td>\n",
       "      <td>0.187179</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.125007</td>\n",
       "      <td>0.191701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317989</td>\n",
       "      <td>-0.059126</td>\n",
       "      <td>0.060694</td>\n",
       "      <td>-0.240812</td>\n",
       "      <td>-0.353171</td>\n",
       "      <td>-0.245768</td>\n",
       "      <td>0.028785</td>\n",
       "      <td>-0.380723</td>\n",
       "      <td>0.092351</td>\n",
       "      <td>0.003392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>-0.112747</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.112288</td>\n",
       "      <td>0.015270</td>\n",
       "      <td>0.358950</td>\n",
       "      <td>-0.140019</td>\n",
       "      <td>-0.048085</td>\n",
       "      <td>0.443256</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>-0.381109</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.319123</td>\n",
       "      <td>-0.064440</td>\n",
       "      <td>0.280409</td>\n",
       "      <td>-0.153190</td>\n",
       "      <td>-0.302358</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.131318</td>\n",
       "      <td>-0.171055</td>\n",
       "      <td>0.157543</td>\n",
       "      <td>-0.110027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>0.079342</td>\n",
       "      <td>0.222737</td>\n",
       "      <td>-0.127458</td>\n",
       "      <td>0.182267</td>\n",
       "      <td>0.539461</td>\n",
       "      <td>0.142528</td>\n",
       "      <td>0.284225</td>\n",
       "      <td>0.344730</td>\n",
       "      <td>0.041001</td>\n",
       "      <td>-0.173703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389716</td>\n",
       "      <td>-0.034679</td>\n",
       "      <td>0.089409</td>\n",
       "      <td>-0.120641</td>\n",
       "      <td>-0.205441</td>\n",
       "      <td>-0.392974</td>\n",
       "      <td>-0.031373</td>\n",
       "      <td>-0.356544</td>\n",
       "      <td>-0.063359</td>\n",
       "      <td>0.228476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>-0.325467</td>\n",
       "      <td>0.364511</td>\n",
       "      <td>-0.311193</td>\n",
       "      <td>-0.188220</td>\n",
       "      <td>0.427008</td>\n",
       "      <td>-0.116094</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.229786</td>\n",
       "      <td>0.189428</td>\n",
       "      <td>0.197744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256529</td>\n",
       "      <td>-0.237647</td>\n",
       "      <td>0.159949</td>\n",
       "      <td>-0.230127</td>\n",
       "      <td>-0.183052</td>\n",
       "      <td>-0.186263</td>\n",
       "      <td>0.319412</td>\n",
       "      <td>-0.201620</td>\n",
       "      <td>-0.080298</td>\n",
       "      <td>0.560703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>0.292430</td>\n",
       "      <td>-0.036102</td>\n",
       "      <td>-0.104375</td>\n",
       "      <td>0.047475</td>\n",
       "      <td>0.415660</td>\n",
       "      <td>-0.263910</td>\n",
       "      <td>0.156837</td>\n",
       "      <td>0.442269</td>\n",
       "      <td>0.057814</td>\n",
       "      <td>-0.299341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386449</td>\n",
       "      <td>-0.211782</td>\n",
       "      <td>0.085755</td>\n",
       "      <td>-0.090621</td>\n",
       "      <td>-0.047417</td>\n",
       "      <td>-0.092715</td>\n",
       "      <td>0.162184</td>\n",
       "      <td>-0.255491</td>\n",
       "      <td>0.238609</td>\n",
       "      <td>0.060878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>-0.100274</td>\n",
       "      <td>-0.059934</td>\n",
       "      <td>0.069847</td>\n",
       "      <td>-0.204302</td>\n",
       "      <td>-0.106762</td>\n",
       "      <td>0.135993</td>\n",
       "      <td>0.207898</td>\n",
       "      <td>0.191095</td>\n",
       "      <td>0.082853</td>\n",
       "      <td>-0.153485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091721</td>\n",
       "      <td>0.143636</td>\n",
       "      <td>-0.064062</td>\n",
       "      <td>-0.112965</td>\n",
       "      <td>-0.437357</td>\n",
       "      <td>0.027483</td>\n",
       "      <td>-0.016705</td>\n",
       "      <td>-0.245427</td>\n",
       "      <td>0.282572</td>\n",
       "      <td>-0.025922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>-0.114071</td>\n",
       "      <td>0.214619</td>\n",
       "      <td>-0.067512</td>\n",
       "      <td>-0.045391</td>\n",
       "      <td>0.193395</td>\n",
       "      <td>-0.165103</td>\n",
       "      <td>-0.194283</td>\n",
       "      <td>0.342020</td>\n",
       "      <td>-0.007280</td>\n",
       "      <td>-0.202092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238062</td>\n",
       "      <td>-0.302890</td>\n",
       "      <td>0.069553</td>\n",
       "      <td>-0.170644</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>-0.161715</td>\n",
       "      <td>0.022736</td>\n",
       "      <td>-0.006655</td>\n",
       "      <td>0.111827</td>\n",
       "      <td>0.158214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>0.195385</td>\n",
       "      <td>-0.482825</td>\n",
       "      <td>-0.023365</td>\n",
       "      <td>0.164054</td>\n",
       "      <td>0.271170</td>\n",
       "      <td>-0.260683</td>\n",
       "      <td>-0.136569</td>\n",
       "      <td>0.574749</td>\n",
       "      <td>-0.034605</td>\n",
       "      <td>-0.378656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143373</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>-0.118181</td>\n",
       "      <td>0.129766</td>\n",
       "      <td>0.179896</td>\n",
       "      <td>-0.072093</td>\n",
       "      <td>0.090320</td>\n",
       "      <td>-0.141417</td>\n",
       "      <td>0.275970</td>\n",
       "      <td>-0.155528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.155334</td>\n",
       "      <td>-0.066302</td>\n",
       "      <td>-0.234053</td>\n",
       "      <td>-0.194786</td>\n",
       "      <td>0.494109</td>\n",
       "      <td>-0.377950</td>\n",
       "      <td>0.322938</td>\n",
       "      <td>0.220968</td>\n",
       "      <td>0.124121</td>\n",
       "      <td>-0.264229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076902</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.089608</td>\n",
       "      <td>-0.199370</td>\n",
       "      <td>-0.139646</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.209336</td>\n",
       "      <td>-0.222321</td>\n",
       "      <td>0.122464</td>\n",
       "      <td>-0.009236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>-0.093779</td>\n",
       "      <td>-0.286692</td>\n",
       "      <td>-0.242321</td>\n",
       "      <td>-0.041582</td>\n",
       "      <td>0.488457</td>\n",
       "      <td>-0.251026</td>\n",
       "      <td>0.132164</td>\n",
       "      <td>0.065876</td>\n",
       "      <td>0.197060</td>\n",
       "      <td>-0.291714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>-0.158995</td>\n",
       "      <td>-0.063805</td>\n",
       "      <td>-0.154940</td>\n",
       "      <td>-0.107990</td>\n",
       "      <td>-0.073755</td>\n",
       "      <td>0.277890</td>\n",
       "      <td>-0.181039</td>\n",
       "      <td>0.354833</td>\n",
       "      <td>0.180103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>-0.054318</td>\n",
       "      <td>-0.124438</td>\n",
       "      <td>-0.107793</td>\n",
       "      <td>-0.077789</td>\n",
       "      <td>0.245563</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>-0.059712</td>\n",
       "      <td>-0.050585</td>\n",
       "      <td>-0.092578</td>\n",
       "      <td>-0.260259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117176</td>\n",
       "      <td>-0.131934</td>\n",
       "      <td>0.198892</td>\n",
       "      <td>-0.065128</td>\n",
       "      <td>-0.311003</td>\n",
       "      <td>-0.144035</td>\n",
       "      <td>0.120283</td>\n",
       "      <td>-0.131758</td>\n",
       "      <td>0.207042</td>\n",
       "      <td>0.130280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>-0.327300</td>\n",
       "      <td>0.152787</td>\n",
       "      <td>-0.120170</td>\n",
       "      <td>0.076031</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.190480</td>\n",
       "      <td>0.186670</td>\n",
       "      <td>-0.016119</td>\n",
       "      <td>-0.193580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399489</td>\n",
       "      <td>-0.262358</td>\n",
       "      <td>0.091110</td>\n",
       "      <td>-0.309065</td>\n",
       "      <td>-0.017968</td>\n",
       "      <td>-0.186251</td>\n",
       "      <td>-0.195400</td>\n",
       "      <td>-0.072537</td>\n",
       "      <td>0.240680</td>\n",
       "      <td>0.021282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>0.320873</td>\n",
       "      <td>0.318971</td>\n",
       "      <td>0.144804</td>\n",
       "      <td>-0.010470</td>\n",
       "      <td>0.293220</td>\n",
       "      <td>-0.279792</td>\n",
       "      <td>0.024183</td>\n",
       "      <td>0.208942</td>\n",
       "      <td>0.206038</td>\n",
       "      <td>-0.381903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.430552</td>\n",
       "      <td>-0.204369</td>\n",
       "      <td>0.163527</td>\n",
       "      <td>-0.373107</td>\n",
       "      <td>-0.082052</td>\n",
       "      <td>-0.289995</td>\n",
       "      <td>-0.071711</td>\n",
       "      <td>-0.219306</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>0.178082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>-0.131880</td>\n",
       "      <td>0.267598</td>\n",
       "      <td>-0.024607</td>\n",
       "      <td>-0.124340</td>\n",
       "      <td>0.408869</td>\n",
       "      <td>-0.058755</td>\n",
       "      <td>0.191407</td>\n",
       "      <td>0.175319</td>\n",
       "      <td>0.165346</td>\n",
       "      <td>-0.364734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133751</td>\n",
       "      <td>-0.190468</td>\n",
       "      <td>0.020242</td>\n",
       "      <td>-0.095911</td>\n",
       "      <td>-0.045120</td>\n",
       "      <td>0.105073</td>\n",
       "      <td>0.299092</td>\n",
       "      <td>-0.027617</td>\n",
       "      <td>0.202357</td>\n",
       "      <td>0.049041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>-0.276165</td>\n",
       "      <td>0.015303</td>\n",
       "      <td>-0.003720</td>\n",
       "      <td>0.121175</td>\n",
       "      <td>0.134349</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>-0.127424</td>\n",
       "      <td>0.344725</td>\n",
       "      <td>-0.075915</td>\n",
       "      <td>-0.323524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258918</td>\n",
       "      <td>-0.124795</td>\n",
       "      <td>0.209812</td>\n",
       "      <td>-0.187413</td>\n",
       "      <td>-0.066898</td>\n",
       "      <td>-0.016816</td>\n",
       "      <td>-0.085607</td>\n",
       "      <td>-0.000958</td>\n",
       "      <td>0.289149</td>\n",
       "      <td>0.146529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>-0.128428</td>\n",
       "      <td>0.224165</td>\n",
       "      <td>-0.107350</td>\n",
       "      <td>-0.063954</td>\n",
       "      <td>0.247078</td>\n",
       "      <td>0.286542</td>\n",
       "      <td>0.394111</td>\n",
       "      <td>0.345904</td>\n",
       "      <td>0.119657</td>\n",
       "      <td>-0.068252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335937</td>\n",
       "      <td>-0.319413</td>\n",
       "      <td>0.071318</td>\n",
       "      <td>-0.225952</td>\n",
       "      <td>-0.153834</td>\n",
       "      <td>0.055644</td>\n",
       "      <td>0.175840</td>\n",
       "      <td>-0.265816</td>\n",
       "      <td>0.255312</td>\n",
       "      <td>0.218721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>0.148665</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>-0.126912</td>\n",
       "      <td>0.051048</td>\n",
       "      <td>0.385225</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.247444</td>\n",
       "      <td>0.394273</td>\n",
       "      <td>-0.062870</td>\n",
       "      <td>-0.154717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487815</td>\n",
       "      <td>-0.091810</td>\n",
       "      <td>0.126663</td>\n",
       "      <td>-0.215565</td>\n",
       "      <td>-0.165061</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>0.104001</td>\n",
       "      <td>0.197867</td>\n",
       "      <td>-0.035842</td>\n",
       "      <td>-0.047661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.178557</td>\n",
       "      <td>-0.054275</td>\n",
       "      <td>0.212291</td>\n",
       "      <td>0.705839</td>\n",
       "      <td>-0.061122</td>\n",
       "      <td>0.129421</td>\n",
       "      <td>0.395960</td>\n",
       "      <td>0.069546</td>\n",
       "      <td>-0.507563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.554943</td>\n",
       "      <td>-0.090595</td>\n",
       "      <td>0.343612</td>\n",
       "      <td>-0.174216</td>\n",
       "      <td>-0.323638</td>\n",
       "      <td>0.062618</td>\n",
       "      <td>0.064982</td>\n",
       "      <td>-0.432173</td>\n",
       "      <td>0.139530</td>\n",
       "      <td>-0.028947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>-0.237158</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>-0.149272</td>\n",
       "      <td>-0.083066</td>\n",
       "      <td>0.363392</td>\n",
       "      <td>-0.174361</td>\n",
       "      <td>0.254614</td>\n",
       "      <td>0.092293</td>\n",
       "      <td>0.270505</td>\n",
       "      <td>-0.140675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>-0.098180</td>\n",
       "      <td>-0.276759</td>\n",
       "      <td>-0.102069</td>\n",
       "      <td>-0.286057</td>\n",
       "      <td>-0.012595</td>\n",
       "      <td>0.075408</td>\n",
       "      <td>-0.373954</td>\n",
       "      <td>0.055785</td>\n",
       "      <td>0.096859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.105995</td>\n",
       "      <td>-0.135916</td>\n",
       "      <td>0.061503</td>\n",
       "      <td>0.355528</td>\n",
       "      <td>-0.057652</td>\n",
       "      <td>0.286534</td>\n",
       "      <td>0.121483</td>\n",
       "      <td>0.280371</td>\n",
       "      <td>-0.433872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.320521</td>\n",
       "      <td>-0.192273</td>\n",
       "      <td>-0.106286</td>\n",
       "      <td>-0.168054</td>\n",
       "      <td>-0.243248</td>\n",
       "      <td>-0.115187</td>\n",
       "      <td>0.254622</td>\n",
       "      <td>-0.159731</td>\n",
       "      <td>0.052970</td>\n",
       "      <td>0.073073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>-0.188089</td>\n",
       "      <td>0.080490</td>\n",
       "      <td>-0.044553</td>\n",
       "      <td>0.043947</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>0.224869</td>\n",
       "      <td>0.124713</td>\n",
       "      <td>0.184258</td>\n",
       "      <td>0.077969</td>\n",
       "      <td>-0.098679</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123869</td>\n",
       "      <td>-0.397354</td>\n",
       "      <td>-0.055745</td>\n",
       "      <td>-0.127449</td>\n",
       "      <td>-0.250386</td>\n",
       "      <td>-0.032826</td>\n",
       "      <td>-0.137185</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.234729</td>\n",
       "      <td>0.246968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>0.021457</td>\n",
       "      <td>-0.110012</td>\n",
       "      <td>-0.013515</td>\n",
       "      <td>0.099018</td>\n",
       "      <td>0.398979</td>\n",
       "      <td>0.104366</td>\n",
       "      <td>0.101906</td>\n",
       "      <td>0.076009</td>\n",
       "      <td>0.285859</td>\n",
       "      <td>-0.174823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270075</td>\n",
       "      <td>-0.109313</td>\n",
       "      <td>0.211395</td>\n",
       "      <td>-0.238484</td>\n",
       "      <td>-0.230312</td>\n",
       "      <td>-0.086133</td>\n",
       "      <td>0.186410</td>\n",
       "      <td>-0.138542</td>\n",
       "      <td>0.164432</td>\n",
       "      <td>0.145123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>0.034130</td>\n",
       "      <td>-0.112319</td>\n",
       "      <td>-0.225181</td>\n",
       "      <td>0.021920</td>\n",
       "      <td>0.264468</td>\n",
       "      <td>-0.240766</td>\n",
       "      <td>0.259048</td>\n",
       "      <td>0.418474</td>\n",
       "      <td>0.082709</td>\n",
       "      <td>-0.072387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179770</td>\n",
       "      <td>-0.071576</td>\n",
       "      <td>0.198299</td>\n",
       "      <td>-0.269263</td>\n",
       "      <td>-0.353523</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>0.219705</td>\n",
       "      <td>-0.159892</td>\n",
       "      <td>0.246027</td>\n",
       "      <td>0.163733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>-0.291992</td>\n",
       "      <td>0.164255</td>\n",
       "      <td>0.355415</td>\n",
       "      <td>-0.017610</td>\n",
       "      <td>0.173162</td>\n",
       "      <td>-0.065194</td>\n",
       "      <td>-0.107725</td>\n",
       "      <td>0.102253</td>\n",
       "      <td>0.181634</td>\n",
       "      <td>-0.353392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218514</td>\n",
       "      <td>-0.044741</td>\n",
       "      <td>-0.074887</td>\n",
       "      <td>0.278181</td>\n",
       "      <td>-0.076447</td>\n",
       "      <td>0.062442</td>\n",
       "      <td>-0.058422</td>\n",
       "      <td>-0.248356</td>\n",
       "      <td>0.118749</td>\n",
       "      <td>0.217348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>-0.506200</td>\n",
       "      <td>0.065261</td>\n",
       "      <td>0.124789</td>\n",
       "      <td>0.105515</td>\n",
       "      <td>0.257197</td>\n",
       "      <td>0.332261</td>\n",
       "      <td>-0.090134</td>\n",
       "      <td>-0.043336</td>\n",
       "      <td>0.020015</td>\n",
       "      <td>-0.218661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415208</td>\n",
       "      <td>-0.025286</td>\n",
       "      <td>0.039672</td>\n",
       "      <td>0.134798</td>\n",
       "      <td>-0.230920</td>\n",
       "      <td>-0.045772</td>\n",
       "      <td>-0.129712</td>\n",
       "      <td>-0.227692</td>\n",
       "      <td>0.153594</td>\n",
       "      <td>0.385598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>0.262688</td>\n",
       "      <td>0.259216</td>\n",
       "      <td>0.218265</td>\n",
       "      <td>0.189706</td>\n",
       "      <td>0.331061</td>\n",
       "      <td>0.157749</td>\n",
       "      <td>-0.102682</td>\n",
       "      <td>0.166144</td>\n",
       "      <td>-0.039264</td>\n",
       "      <td>-0.334758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041324</td>\n",
       "      <td>0.214738</td>\n",
       "      <td>-0.106428</td>\n",
       "      <td>0.063126</td>\n",
       "      <td>-0.058440</td>\n",
       "      <td>-0.396615</td>\n",
       "      <td>-0.211589</td>\n",
       "      <td>-0.228549</td>\n",
       "      <td>0.035506</td>\n",
       "      <td>0.018825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>-0.276380</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>-0.182463</td>\n",
       "      <td>0.041876</td>\n",
       "      <td>0.514691</td>\n",
       "      <td>-0.079672</td>\n",
       "      <td>0.333802</td>\n",
       "      <td>0.138865</td>\n",
       "      <td>0.252402</td>\n",
       "      <td>-0.261123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412149</td>\n",
       "      <td>-0.328737</td>\n",
       "      <td>-0.038353</td>\n",
       "      <td>-0.300481</td>\n",
       "      <td>-0.124718</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.106741</td>\n",
       "      <td>-0.238457</td>\n",
       "      <td>0.138651</td>\n",
       "      <td>0.368722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1657 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.209471  0.004496 -0.115139  0.155171  0.477535 -0.195618 -0.013060   \n",
       "1     0.110659 -0.038571  0.083564  0.122763  0.229474 -0.293610  0.138813   \n",
       "2    -0.105877 -0.126139 -0.004517  0.353253  0.354069 -0.232021 -0.035967   \n",
       "3    -0.306760 -0.072570 -0.030354 -0.015995  0.274578 -0.018717  0.272740   \n",
       "4     0.015524  0.107056 -0.131454  0.036079  0.357085  0.104878  0.202547   \n",
       "5     0.086325  0.000576  0.049581  0.331226  0.195899 -0.161240 -0.333660   \n",
       "6     0.087262  0.135113  0.010001  0.085915  0.297967  0.039862  0.267242   \n",
       "7     0.125913 -0.294783  0.034882  0.252560  0.392762 -0.150249  0.012134   \n",
       "8    -0.191039 -0.075475 -0.021523  0.143183  0.322996 -0.492606 -0.184364   \n",
       "9     0.114660 -0.129702  0.189297 -0.002228  0.332263 -0.325988  0.274241   \n",
       "10    0.158063 -0.046017  0.037953 -0.045892  0.402241 -0.247476  0.382731   \n",
       "11    0.017336 -0.212728 -0.058866  0.128317  0.458701 -0.227745  0.045674   \n",
       "12   -0.178281 -0.265382  0.255352  0.329565  0.609954 -0.174955  0.166275   \n",
       "13    0.132213 -0.390876 -0.363131 -0.083741  0.464973 -0.307907  0.318645   \n",
       "14   -0.028340  0.085461  0.050545  0.060784  0.536255 -0.145110 -0.135764   \n",
       "15    0.418620  0.526589 -0.023410 -0.331130  0.078320 -0.520944  0.022741   \n",
       "16    0.120116  0.027194  0.145966 -0.084733  0.281918  0.005611  0.255245   \n",
       "17   -0.109449 -0.005876  0.101696 -0.007995  0.156524 -0.199592  0.031817   \n",
       "18    0.263593 -0.130139 -0.035034  0.031464  0.166088 -0.109743  0.455733   \n",
       "19    0.193096  0.212816 -0.004589  0.123028 -0.004695 -0.067322  0.235207   \n",
       "20   -0.064434  0.069352 -0.036050  0.074794  0.168766  0.078829 -0.109721   \n",
       "21    0.046450  0.068138  0.141293  0.090107  0.089019 -0.035811  0.129994   \n",
       "22   -0.510245 -0.098832 -0.089534  0.269089  0.454192 -0.082611  0.215839   \n",
       "23   -0.054064  0.034140  0.000714  0.171971  0.363994 -0.003656  0.044114   \n",
       "24    0.085210  0.154348 -0.304565  0.135836  0.369819 -0.094063  0.009904   \n",
       "25    0.034947  0.265486 -0.164463 -0.164292  0.010458  0.113705  0.299325   \n",
       "26   -0.275341  0.340005 -0.141785  0.116333  0.184926  0.101826  0.324654   \n",
       "27    0.008988  0.076374  0.435919  0.166848  0.487784  0.223516  0.109159   \n",
       "28    0.203956 -0.108057 -0.284082 -0.029245  0.292239 -0.061983  0.131715   \n",
       "29   -0.295167 -0.226582 -0.218571 -0.093558  0.251631 -0.228139 -0.019088   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1627  0.035921 -0.119755 -0.290755  0.223579  0.319290 -0.259933  0.266914   \n",
       "1628  0.041996 -0.002779 -0.331530  0.053845  0.624551 -0.149763  0.097528   \n",
       "1629  0.027175 -0.027428  0.370443  0.163214  0.382040 -0.237298  0.170825   \n",
       "1630  0.291832 -0.098329 -0.170266  0.155142  0.119299 -0.268513  0.187179   \n",
       "1631 -0.112747  0.005317  0.112288  0.015270  0.358950 -0.140019 -0.048085   \n",
       "1632  0.079342  0.222737 -0.127458  0.182267  0.539461  0.142528  0.284225   \n",
       "1633 -0.325467  0.364511 -0.311193 -0.188220  0.427008 -0.116094  0.021895   \n",
       "1634  0.292430 -0.036102 -0.104375  0.047475  0.415660 -0.263910  0.156837   \n",
       "1635 -0.100274 -0.059934  0.069847 -0.204302 -0.106762  0.135993  0.207898   \n",
       "1636 -0.114071  0.214619 -0.067512 -0.045391  0.193395 -0.165103 -0.194283   \n",
       "1637  0.195385 -0.482825 -0.023365  0.164054  0.271170 -0.260683 -0.136569   \n",
       "1638  0.155334 -0.066302 -0.234053 -0.194786  0.494109 -0.377950  0.322938   \n",
       "1639 -0.093779 -0.286692 -0.242321 -0.041582  0.488457 -0.251026  0.132164   \n",
       "1640 -0.054318 -0.124438 -0.107793 -0.077789  0.245563  0.012713 -0.059712   \n",
       "1641 -0.327300  0.152787 -0.120170  0.076031  0.006843  0.000899  0.190480   \n",
       "1642  0.320873  0.318971  0.144804 -0.010470  0.293220 -0.279792  0.024183   \n",
       "1643 -0.131880  0.267598 -0.024607 -0.124340  0.408869 -0.058755  0.191407   \n",
       "1644 -0.276165  0.015303 -0.003720  0.121175  0.134349  0.100220 -0.127424   \n",
       "1645 -0.128428  0.224165 -0.107350 -0.063954  0.247078  0.286542  0.394111   \n",
       "1646  0.148665  0.017986 -0.126912  0.051048  0.385225  0.046132  0.247444   \n",
       "1647  0.285714  0.178557 -0.054275  0.212291  0.705839 -0.061122  0.129421   \n",
       "1648 -0.237158  0.044222 -0.149272 -0.083066  0.363392 -0.174361  0.254614   \n",
       "1649  0.041000  0.105995 -0.135916  0.061503  0.355528 -0.057652  0.286534   \n",
       "1650 -0.188089  0.080490 -0.044553  0.043947  0.059339  0.224869  0.124713   \n",
       "1651  0.021457 -0.110012 -0.013515  0.099018  0.398979  0.104366  0.101906   \n",
       "1652  0.034130 -0.112319 -0.225181  0.021920  0.264468 -0.240766  0.259048   \n",
       "1653 -0.291992  0.164255  0.355415 -0.017610  0.173162 -0.065194 -0.107725   \n",
       "1654 -0.506200  0.065261  0.124789  0.105515  0.257197  0.332261 -0.090134   \n",
       "1655  0.262688  0.259216  0.218265  0.189706  0.331061  0.157749 -0.102682   \n",
       "1656 -0.276380  0.019032 -0.182463  0.041876  0.514691 -0.079672  0.333802   \n",
       "\n",
       "           7         8         9      ...          758       759       760  \\\n",
       "0     0.231690  0.323169 -0.301131    ...    -0.406724 -0.040973 -0.027652   \n",
       "1     0.316974  0.124054 -0.196293    ...    -0.045047  0.011148  0.041355   \n",
       "2     0.070528 -0.000716 -0.277295    ...    -0.259656 -0.303123 -0.236008   \n",
       "3     0.152896  0.272880 -0.403173    ...     0.159280 -0.087001  0.050957   \n",
       "4     0.311471  0.347213 -0.294072    ...    -0.486928 -0.445874  0.028652   \n",
       "5     0.332043 -0.124765  0.001668    ...    -0.218233 -0.162323  0.000013   \n",
       "6     0.216932  0.238011 -0.373344    ...    -0.372051 -0.061580  0.220201   \n",
       "7     0.098217  0.112444 -0.382418    ...    -0.113561 -0.075491  0.008705   \n",
       "8     0.484266 -0.272178 -0.287135    ...    -0.116671 -0.097174  0.232923   \n",
       "9     0.147959  0.345936 -0.199805    ...    -0.062633  0.156715 -0.182623   \n",
       "10    0.358171  0.054929 -0.367211    ...    -0.093414  0.090275  0.267203   \n",
       "11    0.134108  0.190062 -0.312267    ...    -0.237606  0.033079  0.203992   \n",
       "12    0.118757  0.036436 -0.291476    ...     0.174364  0.130891 -0.102295   \n",
       "13    0.538655  0.337443 -0.613057    ...     0.079516 -0.115987  0.222240   \n",
       "14    0.555163  0.046966 -0.263132    ...    -0.012180 -0.135883 -0.148727   \n",
       "15    1.123456 -0.542006  0.232951    ...     0.132977 -0.035942  0.136083   \n",
       "16    0.087583  0.156107 -0.405868    ...    -0.220232 -0.202940  0.237187   \n",
       "17    0.333881  0.195976 -0.435123    ...    -0.449158  0.090733  0.223597   \n",
       "18    0.532889  0.081759 -0.414516    ...    -0.460686 -0.134049  0.244823   \n",
       "19    0.248815 -0.011291 -0.162872    ...    -0.454678  0.040477  0.110328   \n",
       "20    0.048042  0.202647 -0.474558    ...    -0.181724 -0.215792 -0.060156   \n",
       "21    0.034573  0.174285 -0.176147    ...    -0.217916 -0.019270  0.121075   \n",
       "22    0.172812  0.141612 -0.159059    ...     0.083163  0.069656 -0.124532   \n",
       "23    0.082386  0.107704 -0.152961    ...    -0.412349 -0.103072  0.003801   \n",
       "24    0.525410  0.005467 -0.227735    ...    -0.442147 -0.212807  0.274809   \n",
       "25    0.580719  0.055595  0.164588    ...    -0.242584 -0.362824  0.092887   \n",
       "26    0.576921 -0.131334 -0.192944    ...    -0.071797 -0.331615 -0.084602   \n",
       "27    0.115567 -0.224231 -0.067205    ...     0.190269  0.109330 -0.008540   \n",
       "28    0.324962  0.185225 -0.352440    ...    -0.174547 -0.117017  0.109617   \n",
       "29    0.103263  0.198132 -0.326215    ...    -0.009350 -0.174707 -0.208100   \n",
       "...        ...       ...       ...    ...          ...       ...       ...   \n",
       "1627  0.300501  0.392987 -0.467993    ...    -0.237950 -0.086248  0.103396   \n",
       "1628  0.368561  0.332120 -0.262467    ...    -0.460937 -0.346799 -0.058143   \n",
       "1629  0.055210  0.258049 -0.301305    ...     0.043902  0.185778  0.018572   \n",
       "1630  0.435897  0.125007  0.191701    ...    -0.317989 -0.059126  0.060694   \n",
       "1631  0.443256  0.030199 -0.381109    ...    -0.319123 -0.064440  0.280409   \n",
       "1632  0.344730  0.041001 -0.173703    ...    -0.389716 -0.034679  0.089409   \n",
       "1633  0.229786  0.189428  0.197744    ...    -0.256529 -0.237647  0.159949   \n",
       "1634  0.442269  0.057814 -0.299341    ...    -0.386449 -0.211782  0.085755   \n",
       "1635  0.191095  0.082853 -0.153485    ...     0.091721  0.143636 -0.064062   \n",
       "1636  0.342020 -0.007280 -0.202092    ...    -0.238062 -0.302890  0.069553   \n",
       "1637  0.574749 -0.034605 -0.378656    ...    -0.143373  0.002094 -0.118181   \n",
       "1638  0.220968  0.124121 -0.264229    ...    -0.076902  0.034284  0.089608   \n",
       "1639  0.065876  0.197060 -0.291714    ...    -0.294885 -0.158995 -0.063805   \n",
       "1640 -0.050585 -0.092578 -0.260259    ...     0.117176 -0.131934  0.198892   \n",
       "1641  0.186670 -0.016119 -0.193580    ...    -0.399489 -0.262358  0.091110   \n",
       "1642  0.208942  0.206038 -0.381903    ...    -0.430552 -0.204369  0.163527   \n",
       "1643  0.175319  0.165346 -0.364734    ...    -0.133751 -0.190468  0.020242   \n",
       "1644  0.344725 -0.075915 -0.323524    ...    -0.258918 -0.124795  0.209812   \n",
       "1645  0.345904  0.119657 -0.068252    ...    -0.335937 -0.319413  0.071318   \n",
       "1646  0.394273 -0.062870 -0.154717    ...    -0.487815 -0.091810  0.126663   \n",
       "1647  0.395960  0.069546 -0.507563    ...    -0.554943 -0.090595  0.343612   \n",
       "1648  0.092293  0.270505 -0.140675    ...    -0.004856 -0.098180 -0.276759   \n",
       "1649  0.121483  0.280371 -0.433872    ...    -0.320521 -0.192273 -0.106286   \n",
       "1650  0.184258  0.077969 -0.098679    ...    -0.123869 -0.397354 -0.055745   \n",
       "1651  0.076009  0.285859 -0.174823    ...    -0.270075 -0.109313  0.211395   \n",
       "1652  0.418474  0.082709 -0.072387    ...    -0.179770 -0.071576  0.198299   \n",
       "1653  0.102253  0.181634 -0.353392    ...     0.218514 -0.044741 -0.074887   \n",
       "1654 -0.043336  0.020015 -0.218661    ...     0.415208 -0.025286  0.039672   \n",
       "1655  0.166144 -0.039264 -0.334758    ...     0.041324  0.214738 -0.106428   \n",
       "1656  0.138865  0.252402 -0.261123    ...    -0.412149 -0.328737 -0.038353   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0    -0.111346 -0.153751  0.059796  0.271627 -0.166859  0.266631  0.047705  \n",
       "1    -0.202223 -0.124132 -0.032951  0.210262  0.048532 -0.073355  0.153868  \n",
       "2    -0.048549 -0.055279  0.216803  0.012138 -0.366128  0.102854  0.375488  \n",
       "3     0.070430 -0.106263  0.094872  0.043582 -0.020065  0.508369  0.091591  \n",
       "4    -0.181518 -0.186059  0.195187  0.094222 -0.200974  0.422862  0.386694  \n",
       "5    -0.259459 -0.218776 -0.109985  0.111837 -0.036943  0.089155 -0.009786  \n",
       "6    -0.275639 -0.227072  0.027100  0.359274 -0.344252  0.250150  0.117292  \n",
       "7    -0.176691 -0.428926 -0.254321  0.388297 -0.185857  0.239657 -0.030906  \n",
       "8    -0.392272 -0.257715 -0.263478 -0.079174  0.080497  0.236805 -0.225707  \n",
       "9    -0.198911 -0.137349  0.023985  0.108520 -0.312357  0.231118  0.127369  \n",
       "10   -0.237173  0.008965 -0.228276  0.198818 -0.045617  0.082915  0.083829  \n",
       "11   -0.315152 -0.370223 -0.258419  0.258914 -0.205614  0.404592 -0.108580  \n",
       "12   -0.063202 -0.436743 -0.129528  0.219512 -0.235703  0.291222  0.181057  \n",
       "13   -0.045644 -0.019237  0.232199  0.452438 -0.357158  0.468553 -0.106071  \n",
       "14   -0.093363 -0.367104  0.211227  0.130208 -0.203195  0.220710  0.375449  \n",
       "15   -0.268821 -0.329891 -0.170559  0.208345 -0.491415 -0.110553  0.006148  \n",
       "16   -0.403492 -0.355451 -0.181120  0.177935 -0.048403  0.048722  0.356045  \n",
       "17   -0.322486 -0.397208 -0.059772  0.211373 -0.187711  0.141056  0.025794  \n",
       "18   -0.179731 -0.134949  0.078633 -0.105364 -0.393908  0.340045  0.096414  \n",
       "19   -0.057601 -0.126198 -0.103152  0.113725 -0.316052  0.267714  0.053662  \n",
       "20   -0.224164 -0.135071 -0.056238 -0.208722  0.083292  0.301749  0.227606  \n",
       "21   -0.169939 -0.289092 -0.301424  0.091092 -0.086131  0.274272  0.136629  \n",
       "22   -0.295635 -0.422188 -0.076995 -0.215519 -0.289105  0.380795  0.048172  \n",
       "23   -0.157215 -0.006288  0.103977  0.203302 -0.271420  0.141007  0.117431  \n",
       "24   -0.186856 -0.167920  0.110090  0.143938 -0.115060  0.093233 -0.117235  \n",
       "25   -0.116698 -0.127281 -0.169401  0.059915 -0.295112  0.115782  0.055739  \n",
       "26   -0.160845 -0.164488  0.037604 -0.091446 -0.153977  0.335259 -0.146477  \n",
       "27   -0.029086 -0.225280 -0.115866 -0.213113 -0.181627  0.340574  0.186039  \n",
       "28   -0.115091 -0.257063  0.001756  0.071385 -0.388143  0.074600  0.120843  \n",
       "29   -0.137720 -0.218207 -0.111663  0.081920 -0.166327  0.264691  0.048727  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1627 -0.030517 -0.372285  0.036003  0.427573 -0.407655  0.251529  0.136620  \n",
       "1628 -0.118170 -0.049363 -0.171821  0.296658 -0.348678  0.240472  0.022283  \n",
       "1629 -0.354997 -0.215179  0.044193 -0.010451 -0.432368  0.170202 -0.072244  \n",
       "1630 -0.240812 -0.353171 -0.245768  0.028785 -0.380723  0.092351  0.003392  \n",
       "1631 -0.153190 -0.302358  0.002281  0.131318 -0.171055  0.157543 -0.110027  \n",
       "1632 -0.120641 -0.205441 -0.392974 -0.031373 -0.356544 -0.063359  0.228476  \n",
       "1633 -0.230127 -0.183052 -0.186263  0.319412 -0.201620 -0.080298  0.560703  \n",
       "1634 -0.090621 -0.047417 -0.092715  0.162184 -0.255491  0.238609  0.060878  \n",
       "1635 -0.112965 -0.437357  0.027483 -0.016705 -0.245427  0.282572 -0.025922  \n",
       "1636 -0.170644  0.001071 -0.161715  0.022736 -0.006655  0.111827  0.158214  \n",
       "1637  0.129766  0.179896 -0.072093  0.090320 -0.141417  0.275970 -0.155528  \n",
       "1638 -0.199370 -0.139646  0.003949  0.209336 -0.222321  0.122464 -0.009236  \n",
       "1639 -0.154940 -0.107990 -0.073755  0.277890 -0.181039  0.354833  0.180103  \n",
       "1640 -0.065128 -0.311003 -0.144035  0.120283 -0.131758  0.207042  0.130280  \n",
       "1641 -0.309065 -0.017968 -0.186251 -0.195400 -0.072537  0.240680  0.021282  \n",
       "1642 -0.373107 -0.082052 -0.289995 -0.071711 -0.219306  0.024464  0.178082  \n",
       "1643 -0.095911 -0.045120  0.105073  0.299092 -0.027617  0.202357  0.049041  \n",
       "1644 -0.187413 -0.066898 -0.016816 -0.085607 -0.000958  0.289149  0.146529  \n",
       "1645 -0.225952 -0.153834  0.055644  0.175840 -0.265816  0.255312  0.218721  \n",
       "1646 -0.215565 -0.165061 -0.280660  0.104001  0.197867 -0.035842 -0.047661  \n",
       "1647 -0.174216 -0.323638  0.062618  0.064982 -0.432173  0.139530 -0.028947  \n",
       "1648 -0.102069 -0.286057 -0.012595  0.075408 -0.373954  0.055785  0.096859  \n",
       "1649 -0.168054 -0.243248 -0.115187  0.254622 -0.159731  0.052970  0.073073  \n",
       "1650 -0.127449 -0.250386 -0.032826 -0.137185  0.008133  0.234729  0.246968  \n",
       "1651 -0.238484 -0.230312 -0.086133  0.186410 -0.138542  0.164432  0.145123  \n",
       "1652 -0.269263 -0.353523  0.008557  0.219705 -0.159892  0.246027  0.163733  \n",
       "1653  0.278181 -0.076447  0.062442 -0.058422 -0.248356  0.118749  0.217348  \n",
       "1654  0.134798 -0.230920 -0.045772 -0.129712 -0.227692  0.153594  0.385598  \n",
       "1655  0.063126 -0.058440 -0.396615 -0.211589 -0.228549  0.035506  0.018825  \n",
       "1656 -0.300481 -0.124718  0.002956  0.106741 -0.238457  0.138651  0.368722  \n",
       "\n",
       "[1657 rows x 768 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tfidf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
